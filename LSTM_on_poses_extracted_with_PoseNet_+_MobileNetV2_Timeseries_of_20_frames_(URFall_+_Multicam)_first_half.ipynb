{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "LSTM on poses extracted with PoseNet + MobileNetV2 - Timeseries of 20 frames - (URFall + Multicam) first half.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrea-Apicella/Fall_Detection/blob/main/LSTM_on_poses_extracted_with_PoseNet_%2B_MobileNetV2_Timeseries_of_20_frames_(URFall_%2B_Multicam)_first_half.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKss9qLlnWda"
      },
      "source": [
        "#LSTM for Fall Detection (+ MobileNetV2)\n",
        "On poses extracted with PoseNet and MobileNetV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CDUkuBEnfB3"
      },
      "source": [
        "##Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKqkc7JCmgZD"
      },
      "source": [
        "# LIBRARIES AND UTILITIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from numpy import genfromtxt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwsEgJJRnqmU"
      },
      "source": [
        "##Utility Functions\n",
        "For loading features and generating one label for each time series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm6eN5w0mgZE"
      },
      "source": [
        "#For loading features and producing shape (numSeries, 20, 34)\n",
        "def load_X(X_path):\n",
        "    '''Loads features (posenet joints) and parses them in series of \"serie_length\" elements'''\n",
        "    file = open(X_path, 'r')\n",
        "    X_= np.array(\n",
        "        [elem for elem in [\n",
        "            row.split(',') for row in file\n",
        "        ]], \n",
        "        dtype=np.float32\n",
        "    )\n",
        "    file.close()\n",
        "    blocks = int(len(X_) / serie_length)\n",
        "    \n",
        "    X_ = np.array(np.split(X_,blocks))\n",
        "\n",
        "    return X_ "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zar86eximgZE"
      },
      "source": [
        "# DEFINING A FUNCTION TO HAVE ONE LABEL FOR EACH SERIE OF serie_length POSES\n",
        "def condense_labels(labels, serie_length):\n",
        "    \"\"\"Condenses n labels in 1 choosing the most frequent among the n ones, where n is serie_length \"\"\"\n",
        "    if (len(labels) % serie_length) == 0:\n",
        "        num_groups = len(labels) / serie_length\n",
        "        groups = np.split(labels , num_groups)\n",
        "        output=[]\n",
        "        for group in groups:\n",
        "            listed = group.tolist()\n",
        "            for label in listed:\n",
        "                a = listed.count(1)\n",
        "                b = listed.count(0)\n",
        "            newvalue = {a : '1', b : '0'}\n",
        "            newlabel = newvalue.get(max(newvalue))\n",
        "            output.append(int(newlabel))\n",
        "        return np.asarray(output)\n",
        "    else:\n",
        "      print('Errore: labels not divisible for serie_length')\n",
        "      return"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be5uf9xbnk0q"
      },
      "source": [
        "###Utility variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibln2SHzmn_R",
        "outputId": "b947ef81-17d5-4ad0-db0a-4ce515effcf9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-pOB0Blm1DJ"
      },
      "source": [
        "data_path =  '/content/drive/MyDrive/Colab Notebooks/Tirocinio/Training LSTM su pose estratte'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJQ7o_CpmgZE"
      },
      "source": [
        "# LENGTH OF EACH SERIE OF POSES\n",
        "serie_length = 20"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_AJ5HSvATFx"
      },
      "source": [
        "## Importing and processing Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8YXBIReoQsS"
      },
      "source": [
        "###Import URFall labels\n",
        "URFall labels were provided by the authors of the dataset in a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "YxChSVgWmgZE",
        "outputId": "aa6c1849-6c01-42d8-e463-b1769d73f2a8"
      },
      "source": [
        "# Loading URFall provided CSV file\n",
        "urfd_labels = pd.read_csv( data_path+'/data_rnn_cnn/urfall-cam0-falls.csv',header=None,sep=',' )\n",
        "urfd_labels.head()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fall-01</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>3.1667</td>\n",
              "      <td>2.9098</td>\n",
              "      <td>0.55367</td>\n",
              "      <td>126.0258</td>\n",
              "      <td>1.0324</td>\n",
              "      <td>1899.5366</td>\n",
              "      <td>1055.9988</td>\n",
              "      <td>0.047310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fall-01</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>3.3067</td>\n",
              "      <td>2.9699</td>\n",
              "      <td>0.47876</td>\n",
              "      <td>125.5657</td>\n",
              "      <td>1.1251</td>\n",
              "      <td>2070.1193</td>\n",
              "      <td>1065.9506</td>\n",
              "      <td>0.048175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fall-01</td>\n",
              "      <td>3</td>\n",
              "      <td>-1</td>\n",
              "      <td>3.1408</td>\n",
              "      <td>3.0506</td>\n",
              "      <td>0.54374</td>\n",
              "      <td>123.1570</td>\n",
              "      <td>1.0161</td>\n",
              "      <td>1869.6442</td>\n",
              "      <td>1055.4955</td>\n",
              "      <td>0.050180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fall-01</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>3.4306</td>\n",
              "      <td>3.1435</td>\n",
              "      <td>0.48859</td>\n",
              "      <td>124.5614</td>\n",
              "      <td>1.1251</td>\n",
              "      <td>2070.1193</td>\n",
              "      <td>1076.1464</td>\n",
              "      <td>0.047877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fall-01</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>3.6324</td>\n",
              "      <td>3.3012</td>\n",
              "      <td>0.49744</td>\n",
              "      <td>123.6089</td>\n",
              "      <td>1.1251</td>\n",
              "      <td>2070.1193</td>\n",
              "      <td>1075.5053</td>\n",
              "      <td>0.052543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0   1   2       3   ...      7          8          9         10\n",
              "0  fall-01   1  -1  3.1667  ...  1.0324  1899.5366  1055.9988  0.047310\n",
              "1  fall-01   2  -1  3.3067  ...  1.1251  2070.1193  1065.9506  0.048175\n",
              "2  fall-01   3  -1  3.1408  ...  1.0161  1869.6442  1055.4955  0.050180\n",
              "3  fall-01   4  -1  3.4306  ...  1.1251  2070.1193  1076.1464  0.047877\n",
              "4  fall-01   5  -1  3.6324  ...  1.1251  2070.1193  1075.5053  0.052543\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSgkWkRzomBu",
        "outputId": "fb83a878-434b-4b89-d4ae-6650818203a4"
      },
      "source": [
        "#extracting frames' labels\n",
        "urfd_labels = urfd_labels.iloc[:,2]\n",
        "print('Number of labels: ', len(urfd_labels))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of labels:  2995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-YoegZ1rG0L",
        "outputId": "be68c15c-0c6b-4e64-ee94-3bef5cdea239"
      },
      "source": [
        "#checking number of elements of each URFall class\n",
        "print('Number of labels for each class:\\n', urfd_labels.value_counts())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of labels for each class:\n",
            " -1    1192\n",
            " 1     903\n",
            " 0     900\n",
            "Name: 2, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSLPNNHFpNY2"
      },
      "source": [
        "###Make URFall labels binary\n",
        "By condensing lying down and fall classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiiDoa6bmgZE",
        "outputId": "de84dcd7-b984-4f24-af59-b60db5af64c4"
      },
      "source": [
        "urfd_labels=urfd_labels.replace(0,3) \n",
        "urfd_labels=urfd_labels.replace(-1,0)\n",
        "urfd_labels=urfd_labels.replace(3,1)\n",
        "\n",
        "print('Number of labels for each class:\\n', urfd_labels.value_counts())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of labels for each class:\n",
            " 1    1803\n",
            "0    1192\n",
            "Name: 2, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g2NDZxumgZF",
        "outputId": "40bbf8c4-4248-4a6b-9478-72d62af4ad65"
      },
      "source": [
        "#using only half of the labels\n",
        "urfd_labels=urfd_labels.iloc[:1520]\n",
        "urfd_labels.columns=['labels']\n",
        "print('Number of labels for each class:\\n', urfd_labels.value_counts())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of labels for each class:\n",
            " 1    831\n",
            "0    689\n",
            "Name: 2, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0lJ8SfCrlOL"
      },
      "source": [
        "##Import Multicam labels\n",
        "Labels generated with a script following the structure provided in Multicam's documentation.\n",
        "\n",
        "These are Multicam's first half labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "227RPGN_mgZF",
        "outputId": "ff15d101-8c50-4829-d394-084f315be690"
      },
      "source": [
        "multicam_labels = pd.read_csv(data_path+'/data_rnn_cnn/multicam_labels_1_11_divisible_by_20.csv', header = None)\n",
        "multicam_labels = multicam_labels.iloc[:, 0]\n",
        "print('Multicam labels count:')\n",
        "multicam_labels.value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multicam labels count:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    18184\n",
              "1    12056\n",
              "Name: 0, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhUjHiy24kNu"
      },
      "source": [
        "##Join URFall and Multicam labels\n",
        "to have our combined dataset's first half labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NnoXAyHsJeu",
        "outputId": "d8099486-ebca-4baa-fe27-1892db9b5420"
      },
      "source": [
        "#joining URFall and Multicam labels\n",
        "urfd_multicam_labels = multicam_labels.append(urfd_labels, ignore_index = True)\n",
        "print('Total labels number: ' ,len(urfd_multicam_labels))\n",
        "print('Labels for each class:')\n",
        "print(urfd_multicam_labels.value_counts())\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total labels number:  31760\n",
            "Labels for each class:\n",
            "0    18873\n",
            "1    12887\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiHNPpRs6Jq4"
      },
      "source": [
        "##Condense Labels\n",
        "Using condense_labels function to go from one label per frame to one label per series "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsMCNbM9mgZF",
        "outputId": "86f47f3c-a4ca-4c68-d5a3-7ae0274df820"
      },
      "source": [
        "#using condense_labels function to generate adequate labels for the time series\n",
        "urfd_multicam_labels = condense_labels(urfd_multicam_labels, serie_length)\n",
        "print('Shape of series of poses\\' labels: ', urfd_multicam_labels.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of series of poses' labels:  (1588,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rvbF85H7JPO"
      },
      "source": [
        "##Load poses "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gflSkGPqmgZF",
        "outputId": "20dcc62b-b0f1-4337-f998-a91c8061a490"
      },
      "source": [
        "urfd_multicam_features = load_X(data_path+'/data_rnn_cnn/Multicam_URFD_first_half_MOBILENETV2.csv')\n",
        "print('Series of poses shape: ' , urfd_multicam_features.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Series of poses shape:  (1588, 20, 34)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI9U9oKE7fxe"
      },
      "source": [
        "##Generate Training and Validation splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwhH74QC9GJ0",
        "outputId": "8e2fc2a8-f490-463a-9b71-568ae7c28eb9"
      },
      "source": [
        "input_shape = (None,) + (urfd_multicam_features.shape[1:])\n",
        "print(input_shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 20, 34)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3cx_VjcmgZG"
      },
      "source": [
        "#Splitting dataset into 80% training and 20% validation with train_test_split method from sklearn library\n",
        "X_train, X_test, y_train, y_test = train_test_split(urfd_multicam_features, urfd_multicam_labels, test_size = 0.2, random_state = 4)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB-zlmsi_w4F",
        "outputId": "60c0ae55-00cd-4df8-fd8d-75bad10056d8"
      },
      "source": [
        "#Checking shapes\n",
        "print('X_train shape: ', X_train.shape)\n",
        "print('X_test shape: ', X_test.shape)\n",
        "\n",
        "print('y_train shape: ', y_train.shape)\n",
        "print('y_test shape: ', y_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:  (1270, 20, 34)\n",
            "X_test shape:  (318, 20, 34)\n",
            "y_train shape:  (1270,)\n",
            "y_test shape:  (318,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meOBSADbCpsj"
      },
      "source": [
        "#LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Sy87vlNALah"
      },
      "source": [
        "##Creating the model\n",
        "\n",
        "LSTM with 34 units per layer. Adding more layers or units did not improve the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11UaBkcomgZG",
        "outputId": "569fabd9-2198-4a46-91f9-ef3047c38ce7"
      },
      "source": [
        "#MODEL\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units = 34, batch_input_shape = input_shape, return_sequences = True)) #By not specifying activation, Tensorflow under the hood uses CuDNN layers. These are much faster than standard LSTM and use tanh activation as default.\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(units = 34, return_sequences = False))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = Adam(lr=0.00001), metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 20, 34)            9384      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 20, 34)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 34)                9384      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 34)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 35        \n",
            "=================================================================\n",
            "Total params: 18,803\n",
            "Trainable params: 18,803\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-ZBf1znClPm"
      },
      "source": [
        "##Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXOi4GmmC9dA"
      },
      "source": [
        "#Stops training when the loss does not get better for 100 consecutive epochs \n",
        "early_stop = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 70)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8wResYPmgZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd04beef-95fb-4798-bba9-6ce953774bec"
      },
      "source": [
        "\n",
        "model.fit(X_train,y_train, epochs = 1000, validation_data = (X_test,y_test), callbacks = [early_stop], verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "40/40 [==============================] - 10s 27ms/step - loss: 0.7013 - accuracy: 0.5221 - val_loss: 0.7062 - val_accuracy: 0.5000\n",
            "Epoch 2/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6966 - accuracy: 0.5463 - val_loss: 0.7047 - val_accuracy: 0.5031\n",
            "Epoch 3/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6998 - accuracy: 0.5178 - val_loss: 0.7029 - val_accuracy: 0.5094\n",
            "Epoch 4/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6970 - accuracy: 0.5435 - val_loss: 0.7014 - val_accuracy: 0.5126\n",
            "Epoch 5/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6968 - accuracy: 0.5377 - val_loss: 0.6998 - val_accuracy: 0.5094\n",
            "Epoch 6/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5608 - val_loss: 0.6984 - val_accuracy: 0.5126\n",
            "Epoch 7/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6984 - accuracy: 0.5344 - val_loss: 0.6969 - val_accuracy: 0.5126\n",
            "Epoch 8/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6956 - accuracy: 0.5411 - val_loss: 0.6954 - val_accuracy: 0.5189\n",
            "Epoch 9/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6903 - accuracy: 0.5658 - val_loss: 0.6940 - val_accuracy: 0.5189\n",
            "Epoch 10/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5627 - val_loss: 0.6925 - val_accuracy: 0.5094\n",
            "Epoch 11/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6927 - accuracy: 0.5729 - val_loss: 0.6910 - val_accuracy: 0.5126\n",
            "Epoch 12/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6901 - accuracy: 0.5531 - val_loss: 0.6897 - val_accuracy: 0.5126\n",
            "Epoch 13/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6883 - accuracy: 0.5741 - val_loss: 0.6882 - val_accuracy: 0.5189\n",
            "Epoch 14/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6882 - accuracy: 0.5648 - val_loss: 0.6866 - val_accuracy: 0.5283\n",
            "Epoch 15/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6866 - accuracy: 0.5948 - val_loss: 0.6850 - val_accuracy: 0.5346\n",
            "Epoch 16/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6810 - accuracy: 0.6139 - val_loss: 0.6835 - val_accuracy: 0.5409\n",
            "Epoch 17/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6840 - accuracy: 0.6044 - val_loss: 0.6820 - val_accuracy: 0.5440\n",
            "Epoch 18/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6821 - accuracy: 0.5918 - val_loss: 0.6803 - val_accuracy: 0.5472\n",
            "Epoch 19/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6834 - accuracy: 0.6124 - val_loss: 0.6782 - val_accuracy: 0.5881\n",
            "Epoch 20/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.6782 - accuracy: 0.6023 - val_loss: 0.6764 - val_accuracy: 0.6006\n",
            "Epoch 21/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6769 - accuracy: 0.6282 - val_loss: 0.6743 - val_accuracy: 0.6321\n",
            "Epoch 22/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.6760 - accuracy: 0.6345 - val_loss: 0.6723 - val_accuracy: 0.6635\n",
            "Epoch 23/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.6713 - accuracy: 0.6568 - val_loss: 0.6699 - val_accuracy: 0.6918\n",
            "Epoch 24/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6718 - accuracy: 0.6444 - val_loss: 0.6677 - val_accuracy: 0.7044\n",
            "Epoch 25/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6671 - accuracy: 0.6779 - val_loss: 0.6650 - val_accuracy: 0.7075\n",
            "Epoch 26/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6670 - accuracy: 0.6799 - val_loss: 0.6623 - val_accuracy: 0.7296\n",
            "Epoch 27/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6631 - accuracy: 0.7052 - val_loss: 0.6594 - val_accuracy: 0.7327\n",
            "Epoch 28/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.6595 - accuracy: 0.7080 - val_loss: 0.6563 - val_accuracy: 0.7704\n",
            "Epoch 29/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6606 - accuracy: 0.6932 - val_loss: 0.6532 - val_accuracy: 0.7767\n",
            "Epoch 30/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6564 - accuracy: 0.6859 - val_loss: 0.6498 - val_accuracy: 0.7799\n",
            "Epoch 31/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6533 - accuracy: 0.7068 - val_loss: 0.6463 - val_accuracy: 0.7799\n",
            "Epoch 32/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6456 - accuracy: 0.7380 - val_loss: 0.6422 - val_accuracy: 0.7799\n",
            "Epoch 33/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6461 - accuracy: 0.7175 - val_loss: 0.6384 - val_accuracy: 0.7830\n",
            "Epoch 34/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6483 - accuracy: 0.7217 - val_loss: 0.6338 - val_accuracy: 0.7547\n",
            "Epoch 35/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6443 - accuracy: 0.7244 - val_loss: 0.6295 - val_accuracy: 0.7673\n",
            "Epoch 36/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6429 - accuracy: 0.7270 - val_loss: 0.6249 - val_accuracy: 0.7736\n",
            "Epoch 37/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6354 - accuracy: 0.7349 - val_loss: 0.6207 - val_accuracy: 0.7736\n",
            "Epoch 38/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6297 - accuracy: 0.7424 - val_loss: 0.6160 - val_accuracy: 0.7736\n",
            "Epoch 39/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6220 - accuracy: 0.7306 - val_loss: 0.6109 - val_accuracy: 0.7673\n",
            "Epoch 40/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6218 - accuracy: 0.7368 - val_loss: 0.6058 - val_accuracy: 0.7642\n",
            "Epoch 41/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6199 - accuracy: 0.7382 - val_loss: 0.6013 - val_accuracy: 0.7704\n",
            "Epoch 42/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6142 - accuracy: 0.7265 - val_loss: 0.5964 - val_accuracy: 0.7799\n",
            "Epoch 43/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6098 - accuracy: 0.7394 - val_loss: 0.5919 - val_accuracy: 0.7799\n",
            "Epoch 44/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5984 - accuracy: 0.7503 - val_loss: 0.5874 - val_accuracy: 0.7799\n",
            "Epoch 45/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6030 - accuracy: 0.7354 - val_loss: 0.5830 - val_accuracy: 0.7799\n",
            "Epoch 46/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5923 - accuracy: 0.7561 - val_loss: 0.5784 - val_accuracy: 0.7830\n",
            "Epoch 47/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6056 - accuracy: 0.7197 - val_loss: 0.5741 - val_accuracy: 0.7830\n",
            "Epoch 48/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5882 - accuracy: 0.7602 - val_loss: 0.5700 - val_accuracy: 0.7830\n",
            "Epoch 49/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5912 - accuracy: 0.7523 - val_loss: 0.5664 - val_accuracy: 0.7830\n",
            "Epoch 50/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5884 - accuracy: 0.7339 - val_loss: 0.5620 - val_accuracy: 0.7893\n",
            "Epoch 51/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5836 - accuracy: 0.7402 - val_loss: 0.5589 - val_accuracy: 0.7893\n",
            "Epoch 52/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5841 - accuracy: 0.7410 - val_loss: 0.5551 - val_accuracy: 0.7925\n",
            "Epoch 53/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5808 - accuracy: 0.7505 - val_loss: 0.5518 - val_accuracy: 0.7893\n",
            "Epoch 54/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5886 - accuracy: 0.7333 - val_loss: 0.5485 - val_accuracy: 0.7893\n",
            "Epoch 55/1000\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.5829 - accuracy: 0.7365 - val_loss: 0.5459 - val_accuracy: 0.7862\n",
            "Epoch 56/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5640 - accuracy: 0.7711 - val_loss: 0.5431 - val_accuracy: 0.7862\n",
            "Epoch 57/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5710 - accuracy: 0.7421 - val_loss: 0.5407 - val_accuracy: 0.7830\n",
            "Epoch 58/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5788 - accuracy: 0.7341 - val_loss: 0.5381 - val_accuracy: 0.7830\n",
            "Epoch 59/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5647 - accuracy: 0.7555 - val_loss: 0.5355 - val_accuracy: 0.7830\n",
            "Epoch 60/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5669 - accuracy: 0.7438 - val_loss: 0.5340 - val_accuracy: 0.7830\n",
            "Epoch 61/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5610 - accuracy: 0.7637 - val_loss: 0.5308 - val_accuracy: 0.7830\n",
            "Epoch 62/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5746 - accuracy: 0.7394 - val_loss: 0.5302 - val_accuracy: 0.7799\n",
            "Epoch 63/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5462 - accuracy: 0.7641 - val_loss: 0.5269 - val_accuracy: 0.7830\n",
            "Epoch 64/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5548 - accuracy: 0.7719 - val_loss: 0.5255 - val_accuracy: 0.7799\n",
            "Epoch 65/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5595 - accuracy: 0.7503 - val_loss: 0.5246 - val_accuracy: 0.7799\n",
            "Epoch 66/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5454 - accuracy: 0.7589 - val_loss: 0.5228 - val_accuracy: 0.7799\n",
            "Epoch 67/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5484 - accuracy: 0.7632 - val_loss: 0.5204 - val_accuracy: 0.7799\n",
            "Epoch 68/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5500 - accuracy: 0.7580 - val_loss: 0.5191 - val_accuracy: 0.7799\n",
            "Epoch 69/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5606 - accuracy: 0.7462 - val_loss: 0.5183 - val_accuracy: 0.7799\n",
            "Epoch 70/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5436 - accuracy: 0.7559 - val_loss: 0.5153 - val_accuracy: 0.7767\n",
            "Epoch 71/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5618 - accuracy: 0.7460 - val_loss: 0.5157 - val_accuracy: 0.7799\n",
            "Epoch 72/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5514 - accuracy: 0.7414 - val_loss: 0.5143 - val_accuracy: 0.7799\n",
            "Epoch 73/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5438 - accuracy: 0.7610 - val_loss: 0.5137 - val_accuracy: 0.7799\n",
            "Epoch 74/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5406 - accuracy: 0.7655 - val_loss: 0.5128 - val_accuracy: 0.7799\n",
            "Epoch 75/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5373 - accuracy: 0.7513 - val_loss: 0.5108 - val_accuracy: 0.7799\n",
            "Epoch 76/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5398 - accuracy: 0.7592 - val_loss: 0.5094 - val_accuracy: 0.7799\n",
            "Epoch 77/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5336 - accuracy: 0.7727 - val_loss: 0.5085 - val_accuracy: 0.7799\n",
            "Epoch 78/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5302 - accuracy: 0.7694 - val_loss: 0.5069 - val_accuracy: 0.7799\n",
            "Epoch 79/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5321 - accuracy: 0.7737 - val_loss: 0.5062 - val_accuracy: 0.7799\n",
            "Epoch 80/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5468 - accuracy: 0.7495 - val_loss: 0.5052 - val_accuracy: 0.7799\n",
            "Epoch 81/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5535 - accuracy: 0.7416 - val_loss: 0.5050 - val_accuracy: 0.7830\n",
            "Epoch 82/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5325 - accuracy: 0.7587 - val_loss: 0.5036 - val_accuracy: 0.7830\n",
            "Epoch 83/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5443 - accuracy: 0.7491 - val_loss: 0.5030 - val_accuracy: 0.7830\n",
            "Epoch 84/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5311 - accuracy: 0.7662 - val_loss: 0.5027 - val_accuracy: 0.7862\n",
            "Epoch 85/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5387 - accuracy: 0.7457 - val_loss: 0.5012 - val_accuracy: 0.7862\n",
            "Epoch 86/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5306 - accuracy: 0.7646 - val_loss: 0.5004 - val_accuracy: 0.7862\n",
            "Epoch 87/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5244 - accuracy: 0.7631 - val_loss: 0.4989 - val_accuracy: 0.7862\n",
            "Epoch 88/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5257 - accuracy: 0.7623 - val_loss: 0.4987 - val_accuracy: 0.7893\n",
            "Epoch 89/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5340 - accuracy: 0.7567 - val_loss: 0.4975 - val_accuracy: 0.7893\n",
            "Epoch 90/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5316 - accuracy: 0.7433 - val_loss: 0.4966 - val_accuracy: 0.7893\n",
            "Epoch 91/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5480 - accuracy: 0.7568 - val_loss: 0.4955 - val_accuracy: 0.7893\n",
            "Epoch 92/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5220 - accuracy: 0.7616 - val_loss: 0.4956 - val_accuracy: 0.7925\n",
            "Epoch 93/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5211 - accuracy: 0.7724 - val_loss: 0.4950 - val_accuracy: 0.7925\n",
            "Epoch 94/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5333 - accuracy: 0.7607 - val_loss: 0.4937 - val_accuracy: 0.7925\n",
            "Epoch 95/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5462 - accuracy: 0.7442 - val_loss: 0.4924 - val_accuracy: 0.7925\n",
            "Epoch 96/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5428 - accuracy: 0.7456 - val_loss: 0.4931 - val_accuracy: 0.7925\n",
            "Epoch 97/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5331 - accuracy: 0.7471 - val_loss: 0.4917 - val_accuracy: 0.7925\n",
            "Epoch 98/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5415 - accuracy: 0.7472 - val_loss: 0.4907 - val_accuracy: 0.7925\n",
            "Epoch 99/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5205 - accuracy: 0.7684 - val_loss: 0.4909 - val_accuracy: 0.7956\n",
            "Epoch 100/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5634 - accuracy: 0.7207 - val_loss: 0.4882 - val_accuracy: 0.7925\n",
            "Epoch 101/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5214 - accuracy: 0.7569 - val_loss: 0.4891 - val_accuracy: 0.7925\n",
            "Epoch 102/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5184 - accuracy: 0.7669 - val_loss: 0.4888 - val_accuracy: 0.7925\n",
            "Epoch 103/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5238 - accuracy: 0.7478 - val_loss: 0.4878 - val_accuracy: 0.7925\n",
            "Epoch 104/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5051 - accuracy: 0.7708 - val_loss: 0.4870 - val_accuracy: 0.7925\n",
            "Epoch 105/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5360 - accuracy: 0.7470 - val_loss: 0.4866 - val_accuracy: 0.7925\n",
            "Epoch 106/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5098 - accuracy: 0.7746 - val_loss: 0.4856 - val_accuracy: 0.7925\n",
            "Epoch 107/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5064 - accuracy: 0.7771 - val_loss: 0.4853 - val_accuracy: 0.7862\n",
            "Epoch 108/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4980 - accuracy: 0.7781 - val_loss: 0.4844 - val_accuracy: 0.7925\n",
            "Epoch 109/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5178 - accuracy: 0.7612 - val_loss: 0.4845 - val_accuracy: 0.7862\n",
            "Epoch 110/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5244 - accuracy: 0.7535 - val_loss: 0.4837 - val_accuracy: 0.7862\n",
            "Epoch 111/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5063 - accuracy: 0.7683 - val_loss: 0.4826 - val_accuracy: 0.7862\n",
            "Epoch 112/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5067 - accuracy: 0.7695 - val_loss: 0.4820 - val_accuracy: 0.7862\n",
            "Epoch 113/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5143 - accuracy: 0.7692 - val_loss: 0.4827 - val_accuracy: 0.7830\n",
            "Epoch 114/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5263 - accuracy: 0.7641 - val_loss: 0.4822 - val_accuracy: 0.7830\n",
            "Epoch 115/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5320 - accuracy: 0.7543 - val_loss: 0.4826 - val_accuracy: 0.7830\n",
            "Epoch 116/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5052 - accuracy: 0.7721 - val_loss: 0.4810 - val_accuracy: 0.7830\n",
            "Epoch 117/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5224 - accuracy: 0.7612 - val_loss: 0.4812 - val_accuracy: 0.7830\n",
            "Epoch 118/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5240 - accuracy: 0.7542 - val_loss: 0.4787 - val_accuracy: 0.7830\n",
            "Epoch 119/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5161 - accuracy: 0.7595 - val_loss: 0.4802 - val_accuracy: 0.7830\n",
            "Epoch 120/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5092 - accuracy: 0.7740 - val_loss: 0.4797 - val_accuracy: 0.7862\n",
            "Epoch 121/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5093 - accuracy: 0.7651 - val_loss: 0.4784 - val_accuracy: 0.7830\n",
            "Epoch 122/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5112 - accuracy: 0.7712 - val_loss: 0.4783 - val_accuracy: 0.7862\n",
            "Epoch 123/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5158 - accuracy: 0.7689 - val_loss: 0.4769 - val_accuracy: 0.7862\n",
            "Epoch 124/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4998 - accuracy: 0.7790 - val_loss: 0.4779 - val_accuracy: 0.7893\n",
            "Epoch 125/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5151 - accuracy: 0.7678 - val_loss: 0.4762 - val_accuracy: 0.7862\n",
            "Epoch 126/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5130 - accuracy: 0.7713 - val_loss: 0.4762 - val_accuracy: 0.7862\n",
            "Epoch 127/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5007 - accuracy: 0.7795 - val_loss: 0.4764 - val_accuracy: 0.7862\n",
            "Epoch 128/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4935 - accuracy: 0.7796 - val_loss: 0.4749 - val_accuracy: 0.7862\n",
            "Epoch 129/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5050 - accuracy: 0.7786 - val_loss: 0.4737 - val_accuracy: 0.7893\n",
            "Epoch 130/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5232 - accuracy: 0.7627 - val_loss: 0.4750 - val_accuracy: 0.7862\n",
            "Epoch 131/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5126 - accuracy: 0.7657 - val_loss: 0.4748 - val_accuracy: 0.7893\n",
            "Epoch 132/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5170 - accuracy: 0.7597 - val_loss: 0.4730 - val_accuracy: 0.7893\n",
            "Epoch 133/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5064 - accuracy: 0.7792 - val_loss: 0.4734 - val_accuracy: 0.7862\n",
            "Epoch 134/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4889 - accuracy: 0.7838 - val_loss: 0.4731 - val_accuracy: 0.7893\n",
            "Epoch 135/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5017 - accuracy: 0.7825 - val_loss: 0.4728 - val_accuracy: 0.7862\n",
            "Epoch 136/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4836 - accuracy: 0.7831 - val_loss: 0.4720 - val_accuracy: 0.7893\n",
            "Epoch 137/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5268 - accuracy: 0.7559 - val_loss: 0.4730 - val_accuracy: 0.7925\n",
            "Epoch 138/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5170 - accuracy: 0.7659 - val_loss: 0.4701 - val_accuracy: 0.7862\n",
            "Epoch 139/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5268 - accuracy: 0.7675 - val_loss: 0.4708 - val_accuracy: 0.7987\n",
            "Epoch 140/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4878 - accuracy: 0.7739 - val_loss: 0.4724 - val_accuracy: 0.7925\n",
            "Epoch 141/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4857 - accuracy: 0.7891 - val_loss: 0.4708 - val_accuracy: 0.7893\n",
            "Epoch 142/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4964 - accuracy: 0.7792 - val_loss: 0.4698 - val_accuracy: 0.7925\n",
            "Epoch 143/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5131 - accuracy: 0.7669 - val_loss: 0.4688 - val_accuracy: 0.7925\n",
            "Epoch 144/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4976 - accuracy: 0.7757 - val_loss: 0.4712 - val_accuracy: 0.7956\n",
            "Epoch 145/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4909 - accuracy: 0.7826 - val_loss: 0.4695 - val_accuracy: 0.7925\n",
            "Epoch 146/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4946 - accuracy: 0.7800 - val_loss: 0.4696 - val_accuracy: 0.7956\n",
            "Epoch 147/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5033 - accuracy: 0.7736 - val_loss: 0.4672 - val_accuracy: 0.7862\n",
            "Epoch 148/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5135 - accuracy: 0.7649 - val_loss: 0.4700 - val_accuracy: 0.7956\n",
            "Epoch 149/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4912 - accuracy: 0.7948 - val_loss: 0.4657 - val_accuracy: 0.7893\n",
            "Epoch 150/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5062 - accuracy: 0.7697 - val_loss: 0.4672 - val_accuracy: 0.7987\n",
            "Epoch 151/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5096 - accuracy: 0.7669 - val_loss: 0.4680 - val_accuracy: 0.7956\n",
            "Epoch 152/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5157 - accuracy: 0.7738 - val_loss: 0.4661 - val_accuracy: 0.7956\n",
            "Epoch 153/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4928 - accuracy: 0.7892 - val_loss: 0.4669 - val_accuracy: 0.7987\n",
            "Epoch 154/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5049 - accuracy: 0.7792 - val_loss: 0.4659 - val_accuracy: 0.7987\n",
            "Epoch 155/1000\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.5105 - accuracy: 0.7709 - val_loss: 0.4652 - val_accuracy: 0.7956\n",
            "Epoch 156/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4852 - accuracy: 0.7978 - val_loss: 0.4644 - val_accuracy: 0.7987\n",
            "Epoch 157/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4930 - accuracy: 0.7836 - val_loss: 0.4641 - val_accuracy: 0.7987\n",
            "Epoch 158/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4822 - accuracy: 0.7912 - val_loss: 0.4649 - val_accuracy: 0.7987\n",
            "Epoch 159/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5318 - accuracy: 0.7531 - val_loss: 0.4655 - val_accuracy: 0.8019\n",
            "Epoch 160/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5216 - accuracy: 0.7574 - val_loss: 0.4632 - val_accuracy: 0.7987\n",
            "Epoch 161/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5314 - accuracy: 0.7624 - val_loss: 0.4637 - val_accuracy: 0.7987\n",
            "Epoch 162/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5169 - accuracy: 0.7706 - val_loss: 0.4649 - val_accuracy: 0.8019\n",
            "Epoch 163/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4697 - accuracy: 0.8015 - val_loss: 0.4636 - val_accuracy: 0.7987\n",
            "Epoch 164/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5201 - accuracy: 0.7703 - val_loss: 0.4655 - val_accuracy: 0.8019\n",
            "Epoch 165/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4928 - accuracy: 0.7831 - val_loss: 0.4623 - val_accuracy: 0.7987\n",
            "Epoch 166/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5311 - accuracy: 0.7608 - val_loss: 0.4620 - val_accuracy: 0.7987\n",
            "Epoch 167/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5166 - accuracy: 0.7746 - val_loss: 0.4611 - val_accuracy: 0.7987\n",
            "Epoch 168/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5106 - accuracy: 0.7655 - val_loss: 0.4620 - val_accuracy: 0.7987\n",
            "Epoch 169/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5152 - accuracy: 0.7606 - val_loss: 0.4611 - val_accuracy: 0.7987\n",
            "Epoch 170/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5108 - accuracy: 0.7678 - val_loss: 0.4604 - val_accuracy: 0.7987\n",
            "Epoch 171/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5031 - accuracy: 0.7761 - val_loss: 0.4611 - val_accuracy: 0.7987\n",
            "Epoch 172/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5031 - accuracy: 0.7784 - val_loss: 0.4600 - val_accuracy: 0.7987\n",
            "Epoch 173/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4926 - accuracy: 0.7974 - val_loss: 0.4599 - val_accuracy: 0.7987\n",
            "Epoch 174/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5126 - accuracy: 0.7728 - val_loss: 0.4611 - val_accuracy: 0.8019\n",
            "Epoch 175/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4882 - accuracy: 0.7767 - val_loss: 0.4600 - val_accuracy: 0.7987\n",
            "Epoch 176/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4833 - accuracy: 0.7898 - val_loss: 0.4598 - val_accuracy: 0.8019\n",
            "Epoch 177/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5024 - accuracy: 0.7802 - val_loss: 0.4606 - val_accuracy: 0.8019\n",
            "Epoch 178/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4783 - accuracy: 0.7939 - val_loss: 0.4581 - val_accuracy: 0.8019\n",
            "Epoch 179/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5014 - accuracy: 0.7773 - val_loss: 0.4582 - val_accuracy: 0.8019\n",
            "Epoch 180/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4971 - accuracy: 0.7776 - val_loss: 0.4584 - val_accuracy: 0.8050\n",
            "Epoch 181/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4922 - accuracy: 0.7838 - val_loss: 0.4587 - val_accuracy: 0.8019\n",
            "Epoch 182/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4952 - accuracy: 0.7842 - val_loss: 0.4584 - val_accuracy: 0.8050\n",
            "Epoch 183/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4930 - accuracy: 0.7889 - val_loss: 0.4578 - val_accuracy: 0.8082\n",
            "Epoch 184/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4987 - accuracy: 0.7847 - val_loss: 0.4579 - val_accuracy: 0.8082\n",
            "Epoch 185/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5209 - accuracy: 0.7690 - val_loss: 0.4594 - val_accuracy: 0.8082\n",
            "Epoch 186/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4850 - accuracy: 0.7899 - val_loss: 0.4564 - val_accuracy: 0.8082\n",
            "Epoch 187/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4821 - accuracy: 0.8002 - val_loss: 0.4595 - val_accuracy: 0.8050\n",
            "Epoch 188/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5060 - accuracy: 0.7803 - val_loss: 0.4565 - val_accuracy: 0.8082\n",
            "Epoch 189/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5003 - accuracy: 0.7851 - val_loss: 0.4569 - val_accuracy: 0.8082\n",
            "Epoch 190/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5068 - accuracy: 0.7768 - val_loss: 0.4554 - val_accuracy: 0.8082\n",
            "Epoch 191/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5231 - accuracy: 0.7604 - val_loss: 0.4566 - val_accuracy: 0.8082\n",
            "Epoch 192/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5141 - accuracy: 0.7684 - val_loss: 0.4557 - val_accuracy: 0.8082\n",
            "Epoch 193/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4858 - accuracy: 0.7888 - val_loss: 0.4545 - val_accuracy: 0.8082\n",
            "Epoch 194/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4877 - accuracy: 0.7855 - val_loss: 0.4562 - val_accuracy: 0.8113\n",
            "Epoch 195/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4809 - accuracy: 0.7916 - val_loss: 0.4556 - val_accuracy: 0.8082\n",
            "Epoch 196/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4881 - accuracy: 0.7915 - val_loss: 0.4553 - val_accuracy: 0.8082\n",
            "Epoch 197/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4901 - accuracy: 0.7931 - val_loss: 0.4538 - val_accuracy: 0.8082\n",
            "Epoch 198/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5011 - accuracy: 0.7730 - val_loss: 0.4535 - val_accuracy: 0.8082\n",
            "Epoch 199/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4758 - accuracy: 0.7965 - val_loss: 0.4530 - val_accuracy: 0.8082\n",
            "Epoch 200/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4992 - accuracy: 0.7762 - val_loss: 0.4548 - val_accuracy: 0.8113\n",
            "Epoch 201/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4852 - accuracy: 0.7784 - val_loss: 0.4540 - val_accuracy: 0.8113\n",
            "Epoch 202/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4840 - accuracy: 0.7773 - val_loss: 0.4528 - val_accuracy: 0.8082\n",
            "Epoch 203/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4892 - accuracy: 0.7913 - val_loss: 0.4522 - val_accuracy: 0.8082\n",
            "Epoch 204/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4900 - accuracy: 0.7772 - val_loss: 0.4528 - val_accuracy: 0.8082\n",
            "Epoch 205/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4841 - accuracy: 0.7929 - val_loss: 0.4531 - val_accuracy: 0.8113\n",
            "Epoch 206/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4990 - accuracy: 0.7711 - val_loss: 0.4525 - val_accuracy: 0.8113\n",
            "Epoch 207/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4912 - accuracy: 0.7841 - val_loss: 0.4539 - val_accuracy: 0.8113\n",
            "Epoch 208/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4533 - accuracy: 0.8098 - val_loss: 0.4534 - val_accuracy: 0.8113\n",
            "Epoch 209/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4825 - accuracy: 0.7895 - val_loss: 0.4517 - val_accuracy: 0.8113\n",
            "Epoch 210/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4875 - accuracy: 0.7795 - val_loss: 0.4521 - val_accuracy: 0.8113\n",
            "Epoch 211/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5199 - accuracy: 0.7653 - val_loss: 0.4518 - val_accuracy: 0.8113\n",
            "Epoch 212/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4992 - accuracy: 0.7776 - val_loss: 0.4510 - val_accuracy: 0.8113\n",
            "Epoch 213/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4792 - accuracy: 0.7914 - val_loss: 0.4514 - val_accuracy: 0.8113\n",
            "Epoch 214/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4873 - accuracy: 0.7824 - val_loss: 0.4527 - val_accuracy: 0.8113\n",
            "Epoch 215/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5028 - accuracy: 0.7762 - val_loss: 0.4513 - val_accuracy: 0.8113\n",
            "Epoch 216/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4893 - accuracy: 0.7875 - val_loss: 0.4512 - val_accuracy: 0.8113\n",
            "Epoch 217/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4924 - accuracy: 0.7955 - val_loss: 0.4503 - val_accuracy: 0.8145\n",
            "Epoch 218/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4934 - accuracy: 0.7768 - val_loss: 0.4501 - val_accuracy: 0.8145\n",
            "Epoch 219/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4989 - accuracy: 0.7877 - val_loss: 0.4514 - val_accuracy: 0.8113\n",
            "Epoch 220/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4936 - accuracy: 0.7757 - val_loss: 0.4504 - val_accuracy: 0.8113\n",
            "Epoch 221/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4845 - accuracy: 0.7916 - val_loss: 0.4481 - val_accuracy: 0.8113\n",
            "Epoch 222/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4830 - accuracy: 0.7854 - val_loss: 0.4478 - val_accuracy: 0.8145\n",
            "Epoch 223/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5053 - accuracy: 0.7756 - val_loss: 0.4499 - val_accuracy: 0.8113\n",
            "Epoch 224/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4954 - accuracy: 0.7861 - val_loss: 0.4486 - val_accuracy: 0.8145\n",
            "Epoch 225/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5046 - accuracy: 0.7829 - val_loss: 0.4491 - val_accuracy: 0.8145\n",
            "Epoch 226/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4724 - accuracy: 0.8035 - val_loss: 0.4493 - val_accuracy: 0.8145\n",
            "Epoch 227/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4974 - accuracy: 0.7782 - val_loss: 0.4497 - val_accuracy: 0.8113\n",
            "Epoch 228/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.7996 - val_loss: 0.4477 - val_accuracy: 0.8145\n",
            "Epoch 229/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4864 - accuracy: 0.7876 - val_loss: 0.4485 - val_accuracy: 0.8145\n",
            "Epoch 230/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4837 - accuracy: 0.7926 - val_loss: 0.4473 - val_accuracy: 0.8145\n",
            "Epoch 231/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4852 - accuracy: 0.7872 - val_loss: 0.4470 - val_accuracy: 0.8176\n",
            "Epoch 232/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4984 - accuracy: 0.7773 - val_loss: 0.4478 - val_accuracy: 0.8145\n",
            "Epoch 233/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4849 - accuracy: 0.7899 - val_loss: 0.4475 - val_accuracy: 0.8145\n",
            "Epoch 234/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4988 - accuracy: 0.7788 - val_loss: 0.4476 - val_accuracy: 0.8145\n",
            "Epoch 235/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4674 - accuracy: 0.7907 - val_loss: 0.4479 - val_accuracy: 0.8145\n",
            "Epoch 236/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4995 - accuracy: 0.7786 - val_loss: 0.4474 - val_accuracy: 0.8145\n",
            "Epoch 237/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4846 - accuracy: 0.7941 - val_loss: 0.4466 - val_accuracy: 0.8145\n",
            "Epoch 238/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5024 - accuracy: 0.7810 - val_loss: 0.4461 - val_accuracy: 0.8176\n",
            "Epoch 239/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4955 - accuracy: 0.7844 - val_loss: 0.4477 - val_accuracy: 0.8145\n",
            "Epoch 240/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4891 - accuracy: 0.7750 - val_loss: 0.4475 - val_accuracy: 0.8145\n",
            "Epoch 241/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4717 - accuracy: 0.8072 - val_loss: 0.4470 - val_accuracy: 0.8145\n",
            "Epoch 242/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4834 - accuracy: 0.7960 - val_loss: 0.4460 - val_accuracy: 0.8176\n",
            "Epoch 243/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4870 - accuracy: 0.7863 - val_loss: 0.4450 - val_accuracy: 0.8176\n",
            "Epoch 244/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4931 - accuracy: 0.7894 - val_loss: 0.4481 - val_accuracy: 0.8145\n",
            "Epoch 245/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4867 - accuracy: 0.7849 - val_loss: 0.4468 - val_accuracy: 0.8145\n",
            "Epoch 246/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5051 - accuracy: 0.7713 - val_loss: 0.4458 - val_accuracy: 0.8176\n",
            "Epoch 247/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4814 - accuracy: 0.7910 - val_loss: 0.4462 - val_accuracy: 0.8176\n",
            "Epoch 248/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4559 - accuracy: 0.8152 - val_loss: 0.4466 - val_accuracy: 0.8145\n",
            "Epoch 249/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4771 - accuracy: 0.7947 - val_loss: 0.4460 - val_accuracy: 0.8145\n",
            "Epoch 250/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5018 - accuracy: 0.7796 - val_loss: 0.4472 - val_accuracy: 0.8145\n",
            "Epoch 251/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.7803 - val_loss: 0.4453 - val_accuracy: 0.8176\n",
            "Epoch 252/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4801 - accuracy: 0.7918 - val_loss: 0.4453 - val_accuracy: 0.8176\n",
            "Epoch 253/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5036 - accuracy: 0.7995 - val_loss: 0.4448 - val_accuracy: 0.8176\n",
            "Epoch 254/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4738 - accuracy: 0.7963 - val_loss: 0.4436 - val_accuracy: 0.8176\n",
            "Epoch 255/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4772 - accuracy: 0.7873 - val_loss: 0.4433 - val_accuracy: 0.8176\n",
            "Epoch 256/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.7846 - val_loss: 0.4448 - val_accuracy: 0.8176\n",
            "Epoch 257/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4807 - accuracy: 0.7909 - val_loss: 0.4437 - val_accuracy: 0.8176\n",
            "Epoch 258/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4775 - accuracy: 0.8000 - val_loss: 0.4422 - val_accuracy: 0.8145\n",
            "Epoch 259/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4872 - accuracy: 0.7838 - val_loss: 0.4461 - val_accuracy: 0.8145\n",
            "Epoch 260/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4889 - accuracy: 0.7923 - val_loss: 0.4431 - val_accuracy: 0.8176\n",
            "Epoch 261/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4988 - accuracy: 0.7778 - val_loss: 0.4450 - val_accuracy: 0.8176\n",
            "Epoch 262/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4678 - accuracy: 0.7972 - val_loss: 0.4423 - val_accuracy: 0.8176\n",
            "Epoch 263/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4720 - accuracy: 0.7968 - val_loss: 0.4435 - val_accuracy: 0.8176\n",
            "Epoch 264/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4866 - accuracy: 0.7916 - val_loss: 0.4438 - val_accuracy: 0.8176\n",
            "Epoch 265/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4858 - accuracy: 0.7936 - val_loss: 0.4435 - val_accuracy: 0.8176\n",
            "Epoch 266/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4785 - accuracy: 0.7900 - val_loss: 0.4428 - val_accuracy: 0.8176\n",
            "Epoch 267/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4638 - accuracy: 0.8061 - val_loss: 0.4427 - val_accuracy: 0.8176\n",
            "Epoch 268/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4805 - accuracy: 0.7899 - val_loss: 0.4436 - val_accuracy: 0.8176\n",
            "Epoch 269/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4957 - accuracy: 0.7852 - val_loss: 0.4442 - val_accuracy: 0.8176\n",
            "Epoch 270/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5217 - accuracy: 0.7653 - val_loss: 0.4418 - val_accuracy: 0.8176\n",
            "Epoch 271/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4917 - accuracy: 0.7803 - val_loss: 0.4447 - val_accuracy: 0.8176\n",
            "Epoch 272/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4877 - accuracy: 0.7843 - val_loss: 0.4419 - val_accuracy: 0.8176\n",
            "Epoch 273/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4650 - accuracy: 0.7971 - val_loss: 0.4414 - val_accuracy: 0.8176\n",
            "Epoch 274/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4724 - accuracy: 0.8006 - val_loss: 0.4425 - val_accuracy: 0.8176\n",
            "Epoch 275/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4998 - accuracy: 0.7821 - val_loss: 0.4407 - val_accuracy: 0.8176\n",
            "Epoch 276/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4493 - accuracy: 0.8084 - val_loss: 0.4428 - val_accuracy: 0.8176\n",
            "Epoch 277/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4832 - accuracy: 0.7937 - val_loss: 0.4407 - val_accuracy: 0.8176\n",
            "Epoch 278/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4842 - accuracy: 0.7895 - val_loss: 0.4421 - val_accuracy: 0.8176\n",
            "Epoch 279/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4727 - accuracy: 0.7928 - val_loss: 0.4420 - val_accuracy: 0.8176\n",
            "Epoch 280/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5035 - accuracy: 0.7768 - val_loss: 0.4434 - val_accuracy: 0.8176\n",
            "Epoch 281/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4773 - accuracy: 0.7866 - val_loss: 0.4408 - val_accuracy: 0.8176\n",
            "Epoch 282/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4891 - accuracy: 0.7770 - val_loss: 0.4424 - val_accuracy: 0.8176\n",
            "Epoch 283/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.7738 - val_loss: 0.4413 - val_accuracy: 0.8176\n",
            "Epoch 284/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4690 - accuracy: 0.8025 - val_loss: 0.4397 - val_accuracy: 0.8176\n",
            "Epoch 285/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5009 - accuracy: 0.7691 - val_loss: 0.4426 - val_accuracy: 0.8176\n",
            "Epoch 286/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4850 - accuracy: 0.7798 - val_loss: 0.4410 - val_accuracy: 0.8176\n",
            "Epoch 287/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5176 - accuracy: 0.7718 - val_loss: 0.4402 - val_accuracy: 0.8176\n",
            "Epoch 288/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4849 - accuracy: 0.7887 - val_loss: 0.4406 - val_accuracy: 0.8176\n",
            "Epoch 289/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4877 - accuracy: 0.7891 - val_loss: 0.4406 - val_accuracy: 0.8176\n",
            "Epoch 290/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4781 - accuracy: 0.7912 - val_loss: 0.4414 - val_accuracy: 0.8176\n",
            "Epoch 291/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4835 - accuracy: 0.7810 - val_loss: 0.4406 - val_accuracy: 0.8176\n",
            "Epoch 292/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4803 - accuracy: 0.7881 - val_loss: 0.4406 - val_accuracy: 0.8176\n",
            "Epoch 293/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4869 - accuracy: 0.7739 - val_loss: 0.4402 - val_accuracy: 0.8176\n",
            "Epoch 294/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4767 - accuracy: 0.7936 - val_loss: 0.4397 - val_accuracy: 0.8176\n",
            "Epoch 295/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4885 - accuracy: 0.7801 - val_loss: 0.4404 - val_accuracy: 0.8176\n",
            "Epoch 296/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4747 - accuracy: 0.7889 - val_loss: 0.4392 - val_accuracy: 0.8176\n",
            "Epoch 297/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4642 - accuracy: 0.7950 - val_loss: 0.4395 - val_accuracy: 0.8176\n",
            "Epoch 298/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4581 - accuracy: 0.8138 - val_loss: 0.4397 - val_accuracy: 0.8176\n",
            "Epoch 299/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.7922 - val_loss: 0.4397 - val_accuracy: 0.8176\n",
            "Epoch 300/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4731 - accuracy: 0.8031 - val_loss: 0.4402 - val_accuracy: 0.8176\n",
            "Epoch 301/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4853 - accuracy: 0.7879 - val_loss: 0.4394 - val_accuracy: 0.8176\n",
            "Epoch 302/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4724 - accuracy: 0.7909 - val_loss: 0.4391 - val_accuracy: 0.8176\n",
            "Epoch 303/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4896 - accuracy: 0.7790 - val_loss: 0.4392 - val_accuracy: 0.8176\n",
            "Epoch 304/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4904 - accuracy: 0.7925 - val_loss: 0.4386 - val_accuracy: 0.8176\n",
            "Epoch 305/1000\n",
            "40/40 [==============================] - 0s 12ms/step - loss: 0.4632 - accuracy: 0.7963 - val_loss: 0.4398 - val_accuracy: 0.8145\n",
            "Epoch 306/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4862 - accuracy: 0.7818 - val_loss: 0.4394 - val_accuracy: 0.8145\n",
            "Epoch 307/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4900 - accuracy: 0.7811 - val_loss: 0.4385 - val_accuracy: 0.8176\n",
            "Epoch 308/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4918 - accuracy: 0.7857 - val_loss: 0.4396 - val_accuracy: 0.8145\n",
            "Epoch 309/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4905 - accuracy: 0.7876 - val_loss: 0.4386 - val_accuracy: 0.8145\n",
            "Epoch 310/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4878 - accuracy: 0.7787 - val_loss: 0.4384 - val_accuracy: 0.8145\n",
            "Epoch 311/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4753 - accuracy: 0.7951 - val_loss: 0.4371 - val_accuracy: 0.8176\n",
            "Epoch 312/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4577 - accuracy: 0.7956 - val_loss: 0.4381 - val_accuracy: 0.8145\n",
            "Epoch 313/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4765 - accuracy: 0.7919 - val_loss: 0.4386 - val_accuracy: 0.8145\n",
            "Epoch 314/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4983 - accuracy: 0.7784 - val_loss: 0.4399 - val_accuracy: 0.8145\n",
            "Epoch 315/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4799 - accuracy: 0.7910 - val_loss: 0.4396 - val_accuracy: 0.8145\n",
            "Epoch 316/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4992 - accuracy: 0.7816 - val_loss: 0.4390 - val_accuracy: 0.8145\n",
            "Epoch 317/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4902 - accuracy: 0.7834 - val_loss: 0.4379 - val_accuracy: 0.8145\n",
            "Epoch 318/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4784 - accuracy: 0.7866 - val_loss: 0.4388 - val_accuracy: 0.8145\n",
            "Epoch 319/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4702 - accuracy: 0.7959 - val_loss: 0.4369 - val_accuracy: 0.8145\n",
            "Epoch 320/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4824 - accuracy: 0.7897 - val_loss: 0.4375 - val_accuracy: 0.8145\n",
            "Epoch 321/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4826 - accuracy: 0.7940 - val_loss: 0.4379 - val_accuracy: 0.8145\n",
            "Epoch 322/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5005 - accuracy: 0.7841 - val_loss: 0.4383 - val_accuracy: 0.8145\n",
            "Epoch 323/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4760 - accuracy: 0.7768 - val_loss: 0.4378 - val_accuracy: 0.8145\n",
            "Epoch 324/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4944 - accuracy: 0.7891 - val_loss: 0.4374 - val_accuracy: 0.8145\n",
            "Epoch 325/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4803 - accuracy: 0.7927 - val_loss: 0.4383 - val_accuracy: 0.8145\n",
            "Epoch 326/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5113 - accuracy: 0.7727 - val_loss: 0.4373 - val_accuracy: 0.8145\n",
            "Epoch 327/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4792 - accuracy: 0.7905 - val_loss: 0.4358 - val_accuracy: 0.8113\n",
            "Epoch 328/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4882 - accuracy: 0.7709 - val_loss: 0.4380 - val_accuracy: 0.8145\n",
            "Epoch 329/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4627 - accuracy: 0.7944 - val_loss: 0.4376 - val_accuracy: 0.8145\n",
            "Epoch 330/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4850 - accuracy: 0.7911 - val_loss: 0.4377 - val_accuracy: 0.8145\n",
            "Epoch 331/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.8034 - val_loss: 0.4369 - val_accuracy: 0.8145\n",
            "Epoch 332/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5069 - accuracy: 0.7703 - val_loss: 0.4357 - val_accuracy: 0.8145\n",
            "Epoch 333/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4545 - accuracy: 0.8174 - val_loss: 0.4372 - val_accuracy: 0.8145\n",
            "Epoch 334/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5122 - accuracy: 0.7656 - val_loss: 0.4361 - val_accuracy: 0.8145\n",
            "Epoch 335/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4823 - accuracy: 0.7856 - val_loss: 0.4365 - val_accuracy: 0.8145\n",
            "Epoch 336/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4771 - accuracy: 0.7965 - val_loss: 0.4371 - val_accuracy: 0.8145\n",
            "Epoch 337/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4647 - accuracy: 0.7969 - val_loss: 0.4376 - val_accuracy: 0.8145\n",
            "Epoch 338/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4623 - accuracy: 0.8005 - val_loss: 0.4382 - val_accuracy: 0.8176\n",
            "Epoch 339/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4902 - accuracy: 0.7753 - val_loss: 0.4365 - val_accuracy: 0.8145\n",
            "Epoch 340/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4555 - accuracy: 0.8082 - val_loss: 0.4364 - val_accuracy: 0.8145\n",
            "Epoch 341/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4810 - accuracy: 0.7841 - val_loss: 0.4367 - val_accuracy: 0.8145\n",
            "Epoch 342/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4941 - accuracy: 0.7831 - val_loss: 0.4355 - val_accuracy: 0.8145\n",
            "Epoch 343/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4796 - accuracy: 0.7923 - val_loss: 0.4359 - val_accuracy: 0.8145\n",
            "Epoch 344/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4651 - accuracy: 0.7901 - val_loss: 0.4372 - val_accuracy: 0.8145\n",
            "Epoch 345/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4838 - accuracy: 0.7878 - val_loss: 0.4359 - val_accuracy: 0.8176\n",
            "Epoch 346/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4732 - accuracy: 0.8013 - val_loss: 0.4373 - val_accuracy: 0.8176\n",
            "Epoch 347/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4554 - accuracy: 0.8140 - val_loss: 0.4359 - val_accuracy: 0.8176\n",
            "Epoch 348/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4642 - accuracy: 0.7994 - val_loss: 0.4378 - val_accuracy: 0.8176\n",
            "Epoch 349/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4819 - accuracy: 0.7957 - val_loss: 0.4365 - val_accuracy: 0.8145\n",
            "Epoch 350/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4709 - accuracy: 0.7947 - val_loss: 0.4355 - val_accuracy: 0.8176\n",
            "Epoch 351/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4669 - accuracy: 0.7908 - val_loss: 0.4371 - val_accuracy: 0.8176\n",
            "Epoch 352/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4891 - accuracy: 0.7858 - val_loss: 0.4362 - val_accuracy: 0.8145\n",
            "Epoch 353/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4562 - accuracy: 0.8093 - val_loss: 0.4368 - val_accuracy: 0.8176\n",
            "Epoch 354/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4902 - accuracy: 0.7880 - val_loss: 0.4358 - val_accuracy: 0.8145\n",
            "Epoch 355/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4877 - accuracy: 0.7926 - val_loss: 0.4353 - val_accuracy: 0.8145\n",
            "Epoch 356/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.7970 - val_loss: 0.4365 - val_accuracy: 0.8145\n",
            "Epoch 357/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4965 - accuracy: 0.7790 - val_loss: 0.4367 - val_accuracy: 0.8145\n",
            "Epoch 358/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4843 - accuracy: 0.7745 - val_loss: 0.4348 - val_accuracy: 0.8145\n",
            "Epoch 359/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4479 - accuracy: 0.8020 - val_loss: 0.4362 - val_accuracy: 0.8145\n",
            "Epoch 360/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4663 - accuracy: 0.8037 - val_loss: 0.4351 - val_accuracy: 0.8145\n",
            "Epoch 361/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4694 - accuracy: 0.7989 - val_loss: 0.4363 - val_accuracy: 0.8145\n",
            "Epoch 362/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4575 - accuracy: 0.8096 - val_loss: 0.4361 - val_accuracy: 0.8145\n",
            "Epoch 363/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4965 - accuracy: 0.7845 - val_loss: 0.4353 - val_accuracy: 0.8145\n",
            "Epoch 364/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5004 - accuracy: 0.7670 - val_loss: 0.4354 - val_accuracy: 0.8145\n",
            "Epoch 365/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4495 - accuracy: 0.8084 - val_loss: 0.4353 - val_accuracy: 0.8145\n",
            "Epoch 366/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4627 - accuracy: 0.7948 - val_loss: 0.4347 - val_accuracy: 0.8145\n",
            "Epoch 367/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4781 - accuracy: 0.7906 - val_loss: 0.4355 - val_accuracy: 0.8176\n",
            "Epoch 368/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4845 - accuracy: 0.7866 - val_loss: 0.4352 - val_accuracy: 0.8145\n",
            "Epoch 369/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4798 - accuracy: 0.7925 - val_loss: 0.4347 - val_accuracy: 0.8145\n",
            "Epoch 370/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4610 - accuracy: 0.8067 - val_loss: 0.4351 - val_accuracy: 0.8145\n",
            "Epoch 371/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4810 - accuracy: 0.7857 - val_loss: 0.4347 - val_accuracy: 0.8145\n",
            "Epoch 372/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4884 - accuracy: 0.7769 - val_loss: 0.4345 - val_accuracy: 0.8145\n",
            "Epoch 373/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4604 - accuracy: 0.8039 - val_loss: 0.4341 - val_accuracy: 0.8145\n",
            "Epoch 374/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4722 - accuracy: 0.7959 - val_loss: 0.4331 - val_accuracy: 0.8145\n",
            "Epoch 375/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4612 - accuracy: 0.8017 - val_loss: 0.4354 - val_accuracy: 0.8176\n",
            "Epoch 376/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.7866 - val_loss: 0.4337 - val_accuracy: 0.8113\n",
            "Epoch 377/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4911 - accuracy: 0.7799 - val_loss: 0.4355 - val_accuracy: 0.8176\n",
            "Epoch 378/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4752 - accuracy: 0.7949 - val_loss: 0.4344 - val_accuracy: 0.8145\n",
            "Epoch 379/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4710 - accuracy: 0.7871 - val_loss: 0.4363 - val_accuracy: 0.8176\n",
            "Epoch 380/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4633 - accuracy: 0.8055 - val_loss: 0.4341 - val_accuracy: 0.8145\n",
            "Epoch 381/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.7969 - val_loss: 0.4339 - val_accuracy: 0.8145\n",
            "Epoch 382/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4810 - accuracy: 0.7900 - val_loss: 0.4344 - val_accuracy: 0.8145\n",
            "Epoch 383/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4846 - accuracy: 0.7856 - val_loss: 0.4334 - val_accuracy: 0.8113\n",
            "Epoch 384/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4865 - accuracy: 0.7864 - val_loss: 0.4338 - val_accuracy: 0.8113\n",
            "Epoch 385/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4864 - accuracy: 0.7730 - val_loss: 0.4339 - val_accuracy: 0.8113\n",
            "Epoch 386/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4616 - accuracy: 0.8091 - val_loss: 0.4343 - val_accuracy: 0.8145\n",
            "Epoch 387/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4654 - accuracy: 0.7931 - val_loss: 0.4354 - val_accuracy: 0.8176\n",
            "Epoch 388/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4619 - accuracy: 0.8023 - val_loss: 0.4361 - val_accuracy: 0.8145\n",
            "Epoch 389/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4896 - accuracy: 0.7924 - val_loss: 0.4344 - val_accuracy: 0.8145\n",
            "Epoch 390/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4512 - accuracy: 0.8009 - val_loss: 0.4336 - val_accuracy: 0.8145\n",
            "Epoch 391/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4848 - accuracy: 0.7971 - val_loss: 0.4335 - val_accuracy: 0.8113\n",
            "Epoch 392/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4766 - accuracy: 0.7932 - val_loss: 0.4334 - val_accuracy: 0.8113\n",
            "Epoch 393/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4387 - accuracy: 0.8191 - val_loss: 0.4337 - val_accuracy: 0.8113\n",
            "Epoch 394/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4830 - accuracy: 0.7943 - val_loss: 0.4341 - val_accuracy: 0.8145\n",
            "Epoch 395/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4561 - accuracy: 0.8046 - val_loss: 0.4340 - val_accuracy: 0.8145\n",
            "Epoch 396/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4957 - accuracy: 0.7909 - val_loss: 0.4341 - val_accuracy: 0.8145\n",
            "Epoch 397/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4725 - accuracy: 0.8007 - val_loss: 0.4351 - val_accuracy: 0.8145\n",
            "Epoch 398/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4703 - accuracy: 0.7957 - val_loss: 0.4338 - val_accuracy: 0.8113\n",
            "Epoch 399/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.7890 - val_loss: 0.4344 - val_accuracy: 0.8145\n",
            "Epoch 400/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4648 - accuracy: 0.7990 - val_loss: 0.4343 - val_accuracy: 0.8113\n",
            "Epoch 401/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4856 - accuracy: 0.7937 - val_loss: 0.4349 - val_accuracy: 0.8145\n",
            "Epoch 402/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4538 - accuracy: 0.8034 - val_loss: 0.4346 - val_accuracy: 0.8145\n",
            "Epoch 403/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4598 - accuracy: 0.8036 - val_loss: 0.4337 - val_accuracy: 0.8113\n",
            "Epoch 404/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4697 - accuracy: 0.7972 - val_loss: 0.4347 - val_accuracy: 0.8145\n",
            "Epoch 405/1000\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.4772 - accuracy: 0.7874 - val_loss: 0.4340 - val_accuracy: 0.8113\n",
            "Epoch 406/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4962 - accuracy: 0.7859 - val_loss: 0.4338 - val_accuracy: 0.8113\n",
            "Epoch 407/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4584 - accuracy: 0.8051 - val_loss: 0.4338 - val_accuracy: 0.8113\n",
            "Epoch 408/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4903 - accuracy: 0.7794 - val_loss: 0.4330 - val_accuracy: 0.8113\n",
            "Epoch 409/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.8114 - val_loss: 0.4335 - val_accuracy: 0.8113\n",
            "Epoch 410/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.7963 - val_loss: 0.4340 - val_accuracy: 0.8113\n",
            "Epoch 411/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4654 - accuracy: 0.7972 - val_loss: 0.4338 - val_accuracy: 0.8113\n",
            "Epoch 412/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4799 - accuracy: 0.7778 - val_loss: 0.4332 - val_accuracy: 0.8113\n",
            "Epoch 413/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4777 - accuracy: 0.8000 - val_loss: 0.4332 - val_accuracy: 0.8113\n",
            "Epoch 414/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4577 - accuracy: 0.8077 - val_loss: 0.4332 - val_accuracy: 0.8113\n",
            "Epoch 415/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4708 - accuracy: 0.7988 - val_loss: 0.4336 - val_accuracy: 0.8113\n",
            "Epoch 416/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4741 - accuracy: 0.7967 - val_loss: 0.4334 - val_accuracy: 0.8113\n",
            "Epoch 417/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4814 - accuracy: 0.7892 - val_loss: 0.4323 - val_accuracy: 0.8145\n",
            "Epoch 418/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4841 - accuracy: 0.7860 - val_loss: 0.4331 - val_accuracy: 0.8113\n",
            "Epoch 419/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4564 - accuracy: 0.7995 - val_loss: 0.4328 - val_accuracy: 0.8113\n",
            "Epoch 420/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4702 - accuracy: 0.7981 - val_loss: 0.4329 - val_accuracy: 0.8113\n",
            "Epoch 421/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4848 - accuracy: 0.7818 - val_loss: 0.4324 - val_accuracy: 0.8176\n",
            "Epoch 422/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4695 - accuracy: 0.7911 - val_loss: 0.4324 - val_accuracy: 0.8145\n",
            "Epoch 423/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4449 - accuracy: 0.8136 - val_loss: 0.4330 - val_accuracy: 0.8113\n",
            "Epoch 424/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4942 - accuracy: 0.7805 - val_loss: 0.4332 - val_accuracy: 0.8113\n",
            "Epoch 425/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4858 - accuracy: 0.7932 - val_loss: 0.4317 - val_accuracy: 0.8176\n",
            "Epoch 426/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4619 - accuracy: 0.8075 - val_loss: 0.4329 - val_accuracy: 0.8113\n",
            "Epoch 427/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4764 - accuracy: 0.7964 - val_loss: 0.4359 - val_accuracy: 0.8113\n",
            "Epoch 428/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4619 - accuracy: 0.8053 - val_loss: 0.4328 - val_accuracy: 0.8145\n",
            "Epoch 429/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4905 - accuracy: 0.7890 - val_loss: 0.4346 - val_accuracy: 0.8082\n",
            "Epoch 430/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4596 - accuracy: 0.7966 - val_loss: 0.4329 - val_accuracy: 0.8113\n",
            "Epoch 431/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4794 - accuracy: 0.8005 - val_loss: 0.4327 - val_accuracy: 0.8113\n",
            "Epoch 432/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4644 - accuracy: 0.8066 - val_loss: 0.4328 - val_accuracy: 0.8113\n",
            "Epoch 433/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4613 - accuracy: 0.7930 - val_loss: 0.4327 - val_accuracy: 0.8113\n",
            "Epoch 434/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4937 - accuracy: 0.7791 - val_loss: 0.4346 - val_accuracy: 0.8145\n",
            "Epoch 435/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4778 - accuracy: 0.7950 - val_loss: 0.4329 - val_accuracy: 0.8145\n",
            "Epoch 436/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4501 - accuracy: 0.8010 - val_loss: 0.4320 - val_accuracy: 0.8176\n",
            "Epoch 437/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4664 - accuracy: 0.8078 - val_loss: 0.4339 - val_accuracy: 0.8145\n",
            "Epoch 438/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4543 - accuracy: 0.8117 - val_loss: 0.4338 - val_accuracy: 0.8113\n",
            "Epoch 439/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4517 - accuracy: 0.8021 - val_loss: 0.4333 - val_accuracy: 0.8113\n",
            "Epoch 440/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4739 - accuracy: 0.8000 - val_loss: 0.4317 - val_accuracy: 0.8176\n",
            "Epoch 441/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4836 - accuracy: 0.7851 - val_loss: 0.4320 - val_accuracy: 0.8176\n",
            "Epoch 442/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4485 - accuracy: 0.8185 - val_loss: 0.4337 - val_accuracy: 0.8145\n",
            "Epoch 443/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4396 - accuracy: 0.8189 - val_loss: 0.4328 - val_accuracy: 0.8113\n",
            "Epoch 444/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4475 - accuracy: 0.8068 - val_loss: 0.4327 - val_accuracy: 0.8176\n",
            "Epoch 445/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4741 - accuracy: 0.7983 - val_loss: 0.4325 - val_accuracy: 0.8176\n",
            "Epoch 446/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4724 - accuracy: 0.7991 - val_loss: 0.4321 - val_accuracy: 0.8176\n",
            "Epoch 447/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4752 - accuracy: 0.7981 - val_loss: 0.4333 - val_accuracy: 0.8113\n",
            "Epoch 448/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4467 - accuracy: 0.8170 - val_loss: 0.4333 - val_accuracy: 0.8113\n",
            "Epoch 449/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4663 - accuracy: 0.7946 - val_loss: 0.4322 - val_accuracy: 0.8176\n",
            "Epoch 450/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4563 - accuracy: 0.8026 - val_loss: 0.4333 - val_accuracy: 0.8113\n",
            "Epoch 451/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4398 - accuracy: 0.8158 - val_loss: 0.4322 - val_accuracy: 0.8176\n",
            "Epoch 452/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4761 - accuracy: 0.8040 - val_loss: 0.4336 - val_accuracy: 0.8113\n",
            "Epoch 453/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4780 - accuracy: 0.7921 - val_loss: 0.4332 - val_accuracy: 0.8082\n",
            "Epoch 454/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4542 - accuracy: 0.8052 - val_loss: 0.4336 - val_accuracy: 0.8082\n",
            "Epoch 455/1000\n",
            "40/40 [==============================] - 0s 12ms/step - loss: 0.4798 - accuracy: 0.7887 - val_loss: 0.4322 - val_accuracy: 0.8176\n",
            "Epoch 456/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4779 - accuracy: 0.7952 - val_loss: 0.4327 - val_accuracy: 0.8176\n",
            "Epoch 457/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4855 - accuracy: 0.7790 - val_loss: 0.4330 - val_accuracy: 0.8113\n",
            "Epoch 458/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4345 - accuracy: 0.8190 - val_loss: 0.4320 - val_accuracy: 0.8176\n",
            "Epoch 459/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4990 - accuracy: 0.7745 - val_loss: 0.4331 - val_accuracy: 0.8113\n",
            "Epoch 460/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4432 - accuracy: 0.8204 - val_loss: 0.4343 - val_accuracy: 0.8082\n",
            "Epoch 461/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4828 - accuracy: 0.7952 - val_loss: 0.4323 - val_accuracy: 0.8176\n",
            "Epoch 462/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4556 - accuracy: 0.8022 - val_loss: 0.4322 - val_accuracy: 0.8176\n",
            "Epoch 463/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4577 - accuracy: 0.8027 - val_loss: 0.4318 - val_accuracy: 0.8176\n",
            "Epoch 464/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.7850 - val_loss: 0.4338 - val_accuracy: 0.8082\n",
            "Epoch 465/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4667 - accuracy: 0.8056 - val_loss: 0.4313 - val_accuracy: 0.8176\n",
            "Epoch 466/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4647 - accuracy: 0.7976 - val_loss: 0.4304 - val_accuracy: 0.8176\n",
            "Epoch 467/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4562 - accuracy: 0.8185 - val_loss: 0.4323 - val_accuracy: 0.8176\n",
            "Epoch 468/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4314 - accuracy: 0.8250 - val_loss: 0.4322 - val_accuracy: 0.8176\n",
            "Epoch 469/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4617 - accuracy: 0.7994 - val_loss: 0.4322 - val_accuracy: 0.8176\n",
            "Epoch 470/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4714 - accuracy: 0.7957 - val_loss: 0.4327 - val_accuracy: 0.8145\n",
            "Epoch 471/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.8012 - val_loss: 0.4316 - val_accuracy: 0.8176\n",
            "Epoch 472/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4666 - accuracy: 0.7939 - val_loss: 0.4321 - val_accuracy: 0.8176\n",
            "Epoch 473/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4511 - accuracy: 0.8170 - val_loss: 0.4325 - val_accuracy: 0.8145\n",
            "Epoch 474/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4614 - accuracy: 0.8101 - val_loss: 0.4320 - val_accuracy: 0.8145\n",
            "Epoch 475/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4769 - accuracy: 0.7860 - val_loss: 0.4324 - val_accuracy: 0.8176\n",
            "Epoch 476/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4719 - accuracy: 0.7978 - val_loss: 0.4316 - val_accuracy: 0.8176\n",
            "Epoch 477/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4692 - accuracy: 0.8017 - val_loss: 0.4323 - val_accuracy: 0.8145\n",
            "Epoch 478/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4703 - accuracy: 0.8059 - val_loss: 0.4308 - val_accuracy: 0.8176\n",
            "Epoch 479/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4601 - accuracy: 0.7933 - val_loss: 0.4310 - val_accuracy: 0.8176\n",
            "Epoch 480/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4708 - accuracy: 0.8045 - val_loss: 0.4323 - val_accuracy: 0.8145\n",
            "Epoch 481/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4549 - accuracy: 0.8040 - val_loss: 0.4317 - val_accuracy: 0.8176\n",
            "Epoch 482/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4683 - accuracy: 0.7943 - val_loss: 0.4312 - val_accuracy: 0.8176\n",
            "Epoch 483/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4663 - accuracy: 0.8026 - val_loss: 0.4325 - val_accuracy: 0.8176\n",
            "Epoch 484/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4423 - accuracy: 0.8124 - val_loss: 0.4298 - val_accuracy: 0.8176\n",
            "Epoch 485/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5058 - accuracy: 0.7671 - val_loss: 0.4318 - val_accuracy: 0.8145\n",
            "Epoch 486/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4772 - accuracy: 0.7996 - val_loss: 0.4316 - val_accuracy: 0.8145\n",
            "Epoch 487/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4790 - accuracy: 0.7914 - val_loss: 0.4328 - val_accuracy: 0.8113\n",
            "Epoch 488/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4616 - accuracy: 0.8060 - val_loss: 0.4322 - val_accuracy: 0.8176\n",
            "Epoch 489/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4602 - accuracy: 0.8095 - val_loss: 0.4312 - val_accuracy: 0.8145\n",
            "Epoch 490/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4789 - accuracy: 0.7995 - val_loss: 0.4330 - val_accuracy: 0.8082\n",
            "Epoch 491/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.7965 - val_loss: 0.4321 - val_accuracy: 0.8176\n",
            "Epoch 492/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4683 - accuracy: 0.8003 - val_loss: 0.4308 - val_accuracy: 0.8176\n",
            "Epoch 493/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4990 - accuracy: 0.7902 - val_loss: 0.4309 - val_accuracy: 0.8176\n",
            "Epoch 494/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4501 - accuracy: 0.8104 - val_loss: 0.4324 - val_accuracy: 0.8176\n",
            "Epoch 495/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4605 - accuracy: 0.8051 - val_loss: 0.4308 - val_accuracy: 0.8176\n",
            "Epoch 496/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4605 - accuracy: 0.8073 - val_loss: 0.4302 - val_accuracy: 0.8176\n",
            "Epoch 497/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4635 - accuracy: 0.7905 - val_loss: 0.4300 - val_accuracy: 0.8176\n",
            "Epoch 498/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4768 - accuracy: 0.7978 - val_loss: 0.4311 - val_accuracy: 0.8145\n",
            "Epoch 499/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4618 - accuracy: 0.8088 - val_loss: 0.4312 - val_accuracy: 0.8145\n",
            "Epoch 500/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4250 - accuracy: 0.8196 - val_loss: 0.4315 - val_accuracy: 0.8145\n",
            "Epoch 501/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4595 - accuracy: 0.7999 - val_loss: 0.4312 - val_accuracy: 0.8145\n",
            "Epoch 502/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4774 - accuracy: 0.7985 - val_loss: 0.4316 - val_accuracy: 0.8145\n",
            "Epoch 503/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4814 - accuracy: 0.7814 - val_loss: 0.4315 - val_accuracy: 0.8176\n",
            "Epoch 504/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4399 - accuracy: 0.8264 - val_loss: 0.4323 - val_accuracy: 0.8145\n",
            "Epoch 505/1000\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.4554 - accuracy: 0.7953 - val_loss: 0.4319 - val_accuracy: 0.8208\n",
            "Epoch 506/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4579 - accuracy: 0.8081 - val_loss: 0.4323 - val_accuracy: 0.8082\n",
            "Epoch 507/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4707 - accuracy: 0.7969 - val_loss: 0.4322 - val_accuracy: 0.8176\n",
            "Epoch 508/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4562 - accuracy: 0.8012 - val_loss: 0.4314 - val_accuracy: 0.8176\n",
            "Epoch 509/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4850 - accuracy: 0.7929 - val_loss: 0.4308 - val_accuracy: 0.8176\n",
            "Epoch 510/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4515 - accuracy: 0.8079 - val_loss: 0.4304 - val_accuracy: 0.8145\n",
            "Epoch 511/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4478 - accuracy: 0.8168 - val_loss: 0.4322 - val_accuracy: 0.8145\n",
            "Epoch 512/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4666 - accuracy: 0.7945 - val_loss: 0.4302 - val_accuracy: 0.8145\n",
            "Epoch 513/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4809 - accuracy: 0.7903 - val_loss: 0.4307 - val_accuracy: 0.8145\n",
            "Epoch 514/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5032 - accuracy: 0.7777 - val_loss: 0.4299 - val_accuracy: 0.8145\n",
            "Epoch 515/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4696 - accuracy: 0.8041 - val_loss: 0.4314 - val_accuracy: 0.8176\n",
            "Epoch 516/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4547 - accuracy: 0.8014 - val_loss: 0.4318 - val_accuracy: 0.8176\n",
            "Epoch 517/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4739 - accuracy: 0.7909 - val_loss: 0.4310 - val_accuracy: 0.8176\n",
            "Epoch 518/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4542 - accuracy: 0.8004 - val_loss: 0.4308 - val_accuracy: 0.8145\n",
            "Epoch 519/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4942 - accuracy: 0.7764 - val_loss: 0.4318 - val_accuracy: 0.8176\n",
            "Epoch 520/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4641 - accuracy: 0.8013 - val_loss: 0.4313 - val_accuracy: 0.8176\n",
            "Epoch 521/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4324 - accuracy: 0.8216 - val_loss: 0.4309 - val_accuracy: 0.8145\n",
            "Epoch 522/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4676 - accuracy: 0.8105 - val_loss: 0.4319 - val_accuracy: 0.8176\n",
            "Epoch 523/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4787 - accuracy: 0.7999 - val_loss: 0.4316 - val_accuracy: 0.8176\n",
            "Epoch 524/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4821 - accuracy: 0.7931 - val_loss: 0.4308 - val_accuracy: 0.8145\n",
            "Epoch 525/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4620 - accuracy: 0.7941 - val_loss: 0.4309 - val_accuracy: 0.8145\n",
            "Epoch 526/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4627 - accuracy: 0.7946 - val_loss: 0.4309 - val_accuracy: 0.8176\n",
            "Epoch 527/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4585 - accuracy: 0.7929 - val_loss: 0.4316 - val_accuracy: 0.8176\n",
            "Epoch 528/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4763 - accuracy: 0.7902 - val_loss: 0.4318 - val_accuracy: 0.8176\n",
            "Epoch 529/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4586 - accuracy: 0.7980 - val_loss: 0.4327 - val_accuracy: 0.8082\n",
            "Epoch 530/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4647 - accuracy: 0.7987 - val_loss: 0.4309 - val_accuracy: 0.8145\n",
            "Epoch 531/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4679 - accuracy: 0.7961 - val_loss: 0.4311 - val_accuracy: 0.8145\n",
            "Epoch 532/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4790 - accuracy: 0.7935 - val_loss: 0.4309 - val_accuracy: 0.8176\n",
            "Epoch 533/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4640 - accuracy: 0.7919 - val_loss: 0.4297 - val_accuracy: 0.8145\n",
            "Epoch 534/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4792 - accuracy: 0.7938 - val_loss: 0.4312 - val_accuracy: 0.8176\n",
            "Epoch 535/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4590 - accuracy: 0.8087 - val_loss: 0.4299 - val_accuracy: 0.8145\n",
            "Epoch 536/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4679 - accuracy: 0.8048 - val_loss: 0.4309 - val_accuracy: 0.8145\n",
            "Epoch 537/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4553 - accuracy: 0.8130 - val_loss: 0.4309 - val_accuracy: 0.8176\n",
            "Epoch 538/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4944 - accuracy: 0.7842 - val_loss: 0.4303 - val_accuracy: 0.8145\n",
            "Epoch 539/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4645 - accuracy: 0.7974 - val_loss: 0.4301 - val_accuracy: 0.8145\n",
            "Epoch 540/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.8039 - val_loss: 0.4314 - val_accuracy: 0.8176\n",
            "Epoch 541/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4621 - accuracy: 0.8183 - val_loss: 0.4310 - val_accuracy: 0.8176\n",
            "Epoch 542/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4605 - accuracy: 0.8035 - val_loss: 0.4312 - val_accuracy: 0.8176\n",
            "Epoch 543/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4654 - accuracy: 0.8048 - val_loss: 0.4309 - val_accuracy: 0.8145\n",
            "Epoch 544/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4666 - accuracy: 0.8031 - val_loss: 0.4309 - val_accuracy: 0.8176\n",
            "Epoch 545/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4738 - accuracy: 0.8007 - val_loss: 0.4310 - val_accuracy: 0.8145\n",
            "Epoch 546/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4789 - accuracy: 0.7905 - val_loss: 0.4307 - val_accuracy: 0.8145\n",
            "Epoch 547/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4671 - accuracy: 0.8012 - val_loss: 0.4304 - val_accuracy: 0.8145\n",
            "Epoch 548/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4951 - accuracy: 0.7809 - val_loss: 0.4296 - val_accuracy: 0.8145\n",
            "Epoch 549/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4794 - accuracy: 0.7969 - val_loss: 0.4315 - val_accuracy: 0.8176\n",
            "Epoch 550/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4474 - accuracy: 0.8250 - val_loss: 0.4309 - val_accuracy: 0.8145\n",
            "Epoch 551/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4540 - accuracy: 0.8087 - val_loss: 0.4300 - val_accuracy: 0.8145\n",
            "Epoch 552/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4603 - accuracy: 0.8070 - val_loss: 0.4319 - val_accuracy: 0.8145\n",
            "Epoch 553/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4740 - accuracy: 0.7903 - val_loss: 0.4313 - val_accuracy: 0.8176\n",
            "Epoch 554/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4586 - accuracy: 0.8015 - val_loss: 0.4300 - val_accuracy: 0.8145\n",
            "Epoch 555/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4753 - accuracy: 0.7929 - val_loss: 0.4309 - val_accuracy: 0.8176\n",
            "Epoch 556/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4607 - accuracy: 0.7908 - val_loss: 0.4312 - val_accuracy: 0.8176\n",
            "Epoch 557/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4610 - accuracy: 0.8041 - val_loss: 0.4309 - val_accuracy: 0.8176\n",
            "Epoch 558/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4677 - accuracy: 0.7960 - val_loss: 0.4298 - val_accuracy: 0.8145\n",
            "Epoch 559/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4657 - accuracy: 0.8090 - val_loss: 0.4316 - val_accuracy: 0.8145\n",
            "Epoch 560/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4598 - accuracy: 0.7955 - val_loss: 0.4311 - val_accuracy: 0.8176\n",
            "Epoch 561/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4733 - accuracy: 0.7986 - val_loss: 0.4317 - val_accuracy: 0.8145\n",
            "Epoch 562/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4726 - accuracy: 0.7920 - val_loss: 0.4304 - val_accuracy: 0.8176\n",
            "Epoch 563/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4723 - accuracy: 0.7921 - val_loss: 0.4306 - val_accuracy: 0.8145\n",
            "Epoch 564/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4514 - accuracy: 0.8137 - val_loss: 0.4301 - val_accuracy: 0.8145\n",
            "Epoch 565/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4639 - accuracy: 0.7991 - val_loss: 0.4314 - val_accuracy: 0.8176\n",
            "Epoch 566/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4683 - accuracy: 0.7948 - val_loss: 0.4292 - val_accuracy: 0.8145\n",
            "Epoch 567/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4677 - accuracy: 0.8051 - val_loss: 0.4297 - val_accuracy: 0.8145\n",
            "Epoch 568/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4544 - accuracy: 0.8090 - val_loss: 0.4302 - val_accuracy: 0.8145\n",
            "Epoch 569/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4560 - accuracy: 0.8080 - val_loss: 0.4311 - val_accuracy: 0.8176\n",
            "Epoch 570/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4435 - accuracy: 0.8174 - val_loss: 0.4307 - val_accuracy: 0.8145\n",
            "Epoch 571/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4771 - accuracy: 0.7961 - val_loss: 0.4306 - val_accuracy: 0.8145\n",
            "Epoch 572/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4641 - accuracy: 0.7998 - val_loss: 0.4311 - val_accuracy: 0.8145\n",
            "Epoch 573/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4737 - accuracy: 0.7998 - val_loss: 0.4302 - val_accuracy: 0.8145\n",
            "Epoch 574/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4655 - accuracy: 0.7877 - val_loss: 0.4316 - val_accuracy: 0.8145\n",
            "Epoch 575/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4522 - accuracy: 0.8147 - val_loss: 0.4302 - val_accuracy: 0.8145\n",
            "Epoch 576/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4838 - accuracy: 0.8015 - val_loss: 0.4312 - val_accuracy: 0.8176\n",
            "Epoch 577/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4557 - accuracy: 0.7983 - val_loss: 0.4303 - val_accuracy: 0.8145\n",
            "Epoch 578/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4762 - accuracy: 0.7927 - val_loss: 0.4295 - val_accuracy: 0.8145\n",
            "Epoch 579/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4890 - accuracy: 0.7873 - val_loss: 0.4308 - val_accuracy: 0.8176\n",
            "Epoch 580/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4808 - accuracy: 0.7855 - val_loss: 0.4311 - val_accuracy: 0.8145\n",
            "Epoch 581/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4582 - accuracy: 0.8125 - val_loss: 0.4301 - val_accuracy: 0.8145\n",
            "Epoch 582/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4639 - accuracy: 0.7997 - val_loss: 0.4308 - val_accuracy: 0.8145\n",
            "Epoch 583/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4449 - accuracy: 0.8175 - val_loss: 0.4297 - val_accuracy: 0.8145\n",
            "Epoch 584/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4544 - accuracy: 0.8142 - val_loss: 0.4315 - val_accuracy: 0.8145\n",
            "Epoch 585/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4725 - accuracy: 0.7847 - val_loss: 0.4317 - val_accuracy: 0.8145\n",
            "Epoch 586/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4720 - accuracy: 0.7926 - val_loss: 0.4318 - val_accuracy: 0.8145\n",
            "Epoch 587/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4699 - accuracy: 0.7957 - val_loss: 0.4300 - val_accuracy: 0.8145\n",
            "Epoch 588/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4799 - accuracy: 0.7896 - val_loss: 0.4316 - val_accuracy: 0.8145\n",
            "Epoch 589/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4758 - accuracy: 0.8009 - val_loss: 0.4311 - val_accuracy: 0.8145\n",
            "Epoch 590/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4662 - accuracy: 0.7936 - val_loss: 0.4308 - val_accuracy: 0.8145\n",
            "Epoch 591/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4453 - accuracy: 0.8176 - val_loss: 0.4314 - val_accuracy: 0.8145\n",
            "Epoch 592/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4648 - accuracy: 0.7968 - val_loss: 0.4312 - val_accuracy: 0.8176\n",
            "Epoch 593/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4709 - accuracy: 0.8019 - val_loss: 0.4301 - val_accuracy: 0.8145\n",
            "Epoch 594/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4683 - accuracy: 0.7977 - val_loss: 0.4308 - val_accuracy: 0.8176\n",
            "Epoch 595/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4648 - accuracy: 0.8013 - val_loss: 0.4301 - val_accuracy: 0.8145\n",
            "Epoch 596/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4486 - accuracy: 0.8013 - val_loss: 0.4299 - val_accuracy: 0.8145\n",
            "Epoch 597/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4745 - accuracy: 0.7999 - val_loss: 0.4302 - val_accuracy: 0.8176\n",
            "Epoch 598/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4590 - accuracy: 0.8055 - val_loss: 0.4310 - val_accuracy: 0.8145\n",
            "Epoch 599/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4635 - accuracy: 0.8059 - val_loss: 0.4297 - val_accuracy: 0.8145\n",
            "Epoch 600/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4565 - accuracy: 0.8079 - val_loss: 0.4300 - val_accuracy: 0.8145\n",
            "Epoch 601/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4516 - accuracy: 0.8047 - val_loss: 0.4304 - val_accuracy: 0.8176\n",
            "Epoch 602/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4787 - accuracy: 0.7924 - val_loss: 0.4298 - val_accuracy: 0.8145\n",
            "Epoch 603/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4725 - accuracy: 0.7924 - val_loss: 0.4308 - val_accuracy: 0.8145\n",
            "Epoch 604/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4574 - accuracy: 0.7933 - val_loss: 0.4293 - val_accuracy: 0.8176\n",
            "Epoch 605/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4564 - accuracy: 0.8105 - val_loss: 0.4301 - val_accuracy: 0.8145\n",
            "Epoch 606/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4584 - accuracy: 0.8147 - val_loss: 0.4310 - val_accuracy: 0.8145\n",
            "Epoch 607/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4412 - accuracy: 0.8112 - val_loss: 0.4300 - val_accuracy: 0.8145\n",
            "Epoch 608/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4698 - accuracy: 0.8003 - val_loss: 0.4320 - val_accuracy: 0.8145\n",
            "Epoch 609/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4606 - accuracy: 0.8021 - val_loss: 0.4304 - val_accuracy: 0.8113\n",
            "Epoch 610/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4577 - accuracy: 0.8021 - val_loss: 0.4295 - val_accuracy: 0.8176\n",
            "Epoch 611/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4581 - accuracy: 0.8047 - val_loss: 0.4308 - val_accuracy: 0.8176\n",
            "Epoch 612/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4290 - accuracy: 0.8242 - val_loss: 0.4303 - val_accuracy: 0.8176\n",
            "Epoch 613/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4479 - accuracy: 0.8188 - val_loss: 0.4311 - val_accuracy: 0.8145\n",
            "Epoch 614/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4527 - accuracy: 0.8120 - val_loss: 0.4299 - val_accuracy: 0.8145\n",
            "Epoch 615/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4474 - accuracy: 0.8099 - val_loss: 0.4301 - val_accuracy: 0.8113\n",
            "Epoch 616/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4531 - accuracy: 0.8000 - val_loss: 0.4301 - val_accuracy: 0.8145\n",
            "Epoch 617/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4473 - accuracy: 0.8051 - val_loss: 0.4290 - val_accuracy: 0.8145\n",
            "Epoch 618/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4658 - accuracy: 0.7953 - val_loss: 0.4299 - val_accuracy: 0.8145\n",
            "Epoch 619/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4607 - accuracy: 0.8058 - val_loss: 0.4299 - val_accuracy: 0.8145\n",
            "Epoch 620/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4510 - accuracy: 0.8164 - val_loss: 0.4302 - val_accuracy: 0.8145\n",
            "Epoch 621/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4379 - accuracy: 0.8144 - val_loss: 0.4300 - val_accuracy: 0.8145\n",
            "Epoch 622/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4773 - accuracy: 0.7946 - val_loss: 0.4313 - val_accuracy: 0.8145\n",
            "Epoch 623/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4862 - accuracy: 0.7911 - val_loss: 0.4291 - val_accuracy: 0.8145\n",
            "Epoch 624/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4642 - accuracy: 0.8042 - val_loss: 0.4292 - val_accuracy: 0.8176\n",
            "Epoch 625/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4712 - accuracy: 0.7963 - val_loss: 0.4297 - val_accuracy: 0.8176\n",
            "Epoch 626/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4786 - accuracy: 0.7972 - val_loss: 0.4295 - val_accuracy: 0.8176\n",
            "Epoch 627/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4627 - accuracy: 0.8001 - val_loss: 0.4307 - val_accuracy: 0.8145\n",
            "Epoch 628/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4453 - accuracy: 0.8158 - val_loss: 0.4290 - val_accuracy: 0.8145\n",
            "Epoch 629/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4698 - accuracy: 0.8016 - val_loss: 0.4303 - val_accuracy: 0.8145\n",
            "Epoch 630/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4585 - accuracy: 0.8064 - val_loss: 0.4300 - val_accuracy: 0.8145\n",
            "Epoch 631/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4551 - accuracy: 0.8114 - val_loss: 0.4305 - val_accuracy: 0.8145\n",
            "Epoch 632/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.8393 - val_loss: 0.4315 - val_accuracy: 0.8145\n",
            "Epoch 633/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4405 - accuracy: 0.8127 - val_loss: 0.4295 - val_accuracy: 0.8145\n",
            "Epoch 634/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.8008 - val_loss: 0.4297 - val_accuracy: 0.8145\n",
            "Epoch 635/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4539 - accuracy: 0.8058 - val_loss: 0.4301 - val_accuracy: 0.8145\n",
            "Epoch 636/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4587 - accuracy: 0.8116 - val_loss: 0.4307 - val_accuracy: 0.8145\n",
            "Epoch 637/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4584 - accuracy: 0.7980 - val_loss: 0.4301 - val_accuracy: 0.8176\n",
            "Epoch 638/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4505 - accuracy: 0.8159 - val_loss: 0.4289 - val_accuracy: 0.8145\n",
            "Epoch 639/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4455 - accuracy: 0.8062 - val_loss: 0.4296 - val_accuracy: 0.8145\n",
            "Epoch 640/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4482 - accuracy: 0.8115 - val_loss: 0.4304 - val_accuracy: 0.8113\n",
            "Epoch 641/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4726 - accuracy: 0.7939 - val_loss: 0.4298 - val_accuracy: 0.8176\n",
            "Epoch 642/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4536 - accuracy: 0.8063 - val_loss: 0.4291 - val_accuracy: 0.8145\n",
            "Epoch 643/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4507 - accuracy: 0.8096 - val_loss: 0.4309 - val_accuracy: 0.8145\n",
            "Epoch 644/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4503 - accuracy: 0.8057 - val_loss: 0.4306 - val_accuracy: 0.8145\n",
            "Epoch 645/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4509 - accuracy: 0.8081 - val_loss: 0.4308 - val_accuracy: 0.8113\n",
            "Epoch 646/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4429 - accuracy: 0.8104 - val_loss: 0.4308 - val_accuracy: 0.8145\n",
            "Epoch 647/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4555 - accuracy: 0.7942 - val_loss: 0.4306 - val_accuracy: 0.8145\n",
            "Epoch 648/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4567 - accuracy: 0.8025 - val_loss: 0.4301 - val_accuracy: 0.8176\n",
            "Epoch 649/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4617 - accuracy: 0.7966 - val_loss: 0.4311 - val_accuracy: 0.8145\n",
            "Epoch 650/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4586 - accuracy: 0.8021 - val_loss: 0.4302 - val_accuracy: 0.8176\n",
            "Epoch 651/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4842 - accuracy: 0.7853 - val_loss: 0.4287 - val_accuracy: 0.8145\n",
            "Epoch 652/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4428 - accuracy: 0.8247 - val_loss: 0.4305 - val_accuracy: 0.8176\n",
            "Epoch 653/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4396 - accuracy: 0.8158 - val_loss: 0.4299 - val_accuracy: 0.8176\n",
            "Epoch 654/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4394 - accuracy: 0.8213 - val_loss: 0.4302 - val_accuracy: 0.8176\n",
            "Epoch 655/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4692 - accuracy: 0.8060 - val_loss: 0.4296 - val_accuracy: 0.8145\n",
            "Epoch 656/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4610 - accuracy: 0.8123 - val_loss: 0.4306 - val_accuracy: 0.8145\n",
            "Epoch 657/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4387 - accuracy: 0.8211 - val_loss: 0.4296 - val_accuracy: 0.8113\n",
            "Epoch 658/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4670 - accuracy: 0.8030 - val_loss: 0.4306 - val_accuracy: 0.8145\n",
            "Epoch 659/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4516 - accuracy: 0.8050 - val_loss: 0.4298 - val_accuracy: 0.8176\n",
            "Epoch 660/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4579 - accuracy: 0.8024 - val_loss: 0.4307 - val_accuracy: 0.8145\n",
            "Epoch 661/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4948 - accuracy: 0.7787 - val_loss: 0.4298 - val_accuracy: 0.8176\n",
            "Epoch 662/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4831 - accuracy: 0.7820 - val_loss: 0.4297 - val_accuracy: 0.8145\n",
            "Epoch 663/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4412 - accuracy: 0.8129 - val_loss: 0.4292 - val_accuracy: 0.8145\n",
            "Epoch 664/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4593 - accuracy: 0.8124 - val_loss: 0.4293 - val_accuracy: 0.8145\n",
            "Epoch 665/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4543 - accuracy: 0.8104 - val_loss: 0.4313 - val_accuracy: 0.8145\n",
            "Epoch 666/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4790 - accuracy: 0.7908 - val_loss: 0.4301 - val_accuracy: 0.8145\n",
            "Epoch 667/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4519 - accuracy: 0.8051 - val_loss: 0.4304 - val_accuracy: 0.8176\n",
            "Epoch 668/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4429 - accuracy: 0.8040 - val_loss: 0.4294 - val_accuracy: 0.8145\n",
            "Epoch 669/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4658 - accuracy: 0.8054 - val_loss: 0.4309 - val_accuracy: 0.8145\n",
            "Epoch 670/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4737 - accuracy: 0.7984 - val_loss: 0.4299 - val_accuracy: 0.8145\n",
            "Epoch 671/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4645 - accuracy: 0.8036 - val_loss: 0.4295 - val_accuracy: 0.8145\n",
            "Epoch 672/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4794 - accuracy: 0.7853 - val_loss: 0.4314 - val_accuracy: 0.8145\n",
            "Epoch 673/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4323 - accuracy: 0.8226 - val_loss: 0.4305 - val_accuracy: 0.8145\n",
            "Epoch 674/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4704 - accuracy: 0.8052 - val_loss: 0.4308 - val_accuracy: 0.8145\n",
            "Epoch 675/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.7989 - val_loss: 0.4301 - val_accuracy: 0.8145\n",
            "Epoch 676/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4756 - accuracy: 0.7931 - val_loss: 0.4299 - val_accuracy: 0.8145\n",
            "Epoch 677/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4465 - accuracy: 0.8037 - val_loss: 0.4299 - val_accuracy: 0.8145\n",
            "Epoch 678/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4965 - accuracy: 0.7858 - val_loss: 0.4303 - val_accuracy: 0.8145\n",
            "Epoch 679/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4636 - accuracy: 0.8048 - val_loss: 0.4297 - val_accuracy: 0.8176\n",
            "Epoch 680/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4615 - accuracy: 0.7906 - val_loss: 0.4288 - val_accuracy: 0.8145\n",
            "Epoch 681/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4580 - accuracy: 0.8041 - val_loss: 0.4315 - val_accuracy: 0.8145\n",
            "Epoch 682/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4646 - accuracy: 0.7923 - val_loss: 0.4306 - val_accuracy: 0.8113\n",
            "Epoch 683/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4447 - accuracy: 0.8009 - val_loss: 0.4300 - val_accuracy: 0.8145\n",
            "Epoch 684/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4390 - accuracy: 0.8139 - val_loss: 0.4310 - val_accuracy: 0.8145\n",
            "Epoch 685/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4427 - accuracy: 0.8135 - val_loss: 0.4302 - val_accuracy: 0.8113\n",
            "Epoch 686/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4582 - accuracy: 0.7997 - val_loss: 0.4310 - val_accuracy: 0.8145\n",
            "Epoch 687/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4886 - accuracy: 0.7775 - val_loss: 0.4301 - val_accuracy: 0.8113\n",
            "Epoch 688/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4457 - accuracy: 0.8114 - val_loss: 0.4303 - val_accuracy: 0.8113\n",
            "Epoch 689/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4538 - accuracy: 0.8108 - val_loss: 0.4299 - val_accuracy: 0.8113\n",
            "Epoch 690/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4499 - accuracy: 0.8185 - val_loss: 0.4304 - val_accuracy: 0.8145\n",
            "Epoch 691/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4530 - accuracy: 0.8086 - val_loss: 0.4304 - val_accuracy: 0.8145\n",
            "Epoch 692/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4418 - accuracy: 0.8166 - val_loss: 0.4305 - val_accuracy: 0.8145\n",
            "Epoch 693/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4605 - accuracy: 0.7987 - val_loss: 0.4287 - val_accuracy: 0.8145\n",
            "Epoch 694/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4759 - accuracy: 0.7823 - val_loss: 0.4297 - val_accuracy: 0.8145\n",
            "Epoch 695/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4527 - accuracy: 0.8142 - val_loss: 0.4295 - val_accuracy: 0.8145\n",
            "Epoch 696/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4685 - accuracy: 0.7962 - val_loss: 0.4314 - val_accuracy: 0.8145\n",
            "Epoch 697/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4531 - accuracy: 0.8121 - val_loss: 0.4297 - val_accuracy: 0.8145\n",
            "Epoch 698/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4629 - accuracy: 0.8012 - val_loss: 0.4296 - val_accuracy: 0.8145\n",
            "Epoch 699/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4864 - accuracy: 0.7817 - val_loss: 0.4292 - val_accuracy: 0.8145\n",
            "Epoch 700/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4754 - accuracy: 0.7953 - val_loss: 0.4307 - val_accuracy: 0.8145\n",
            "Epoch 701/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4703 - accuracy: 0.7997 - val_loss: 0.4290 - val_accuracy: 0.8145\n",
            "Epoch 702/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4620 - accuracy: 0.8045 - val_loss: 0.4291 - val_accuracy: 0.8145\n",
            "Epoch 703/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4435 - accuracy: 0.8088 - val_loss: 0.4302 - val_accuracy: 0.8145\n",
            "Epoch 704/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4651 - accuracy: 0.7953 - val_loss: 0.4308 - val_accuracy: 0.8145\n",
            "Epoch 705/1000\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.4566 - accuracy: 0.8017 - val_loss: 0.4301 - val_accuracy: 0.8113\n",
            "Epoch 706/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4827 - accuracy: 0.7879 - val_loss: 0.4318 - val_accuracy: 0.8145\n",
            "Epoch 707/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4875 - accuracy: 0.7874 - val_loss: 0.4302 - val_accuracy: 0.8145\n",
            "Epoch 708/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4612 - accuracy: 0.7990 - val_loss: 0.4308 - val_accuracy: 0.8145\n",
            "Epoch 709/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4513 - accuracy: 0.8098 - val_loss: 0.4298 - val_accuracy: 0.8145\n",
            "Epoch 710/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4611 - accuracy: 0.8041 - val_loss: 0.4302 - val_accuracy: 0.8113\n",
            "Epoch 711/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4348 - accuracy: 0.8184 - val_loss: 0.4305 - val_accuracy: 0.8145\n",
            "Epoch 712/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4363 - accuracy: 0.8285 - val_loss: 0.4295 - val_accuracy: 0.8145\n",
            "Epoch 713/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4498 - accuracy: 0.8102 - val_loss: 0.4302 - val_accuracy: 0.8113\n",
            "Epoch 714/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4347 - accuracy: 0.8161 - val_loss: 0.4290 - val_accuracy: 0.8145\n",
            "Epoch 715/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4372 - accuracy: 0.8142 - val_loss: 0.4307 - val_accuracy: 0.8145\n",
            "Epoch 716/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4516 - accuracy: 0.8107 - val_loss: 0.4304 - val_accuracy: 0.8145\n",
            "Epoch 717/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4625 - accuracy: 0.8079 - val_loss: 0.4312 - val_accuracy: 0.8145\n",
            "Epoch 718/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4378 - accuracy: 0.8065 - val_loss: 0.4302 - val_accuracy: 0.8113\n",
            "Epoch 719/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4542 - accuracy: 0.8118 - val_loss: 0.4288 - val_accuracy: 0.8176\n",
            "Epoch 720/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4573 - accuracy: 0.8003 - val_loss: 0.4308 - val_accuracy: 0.8176\n",
            "Epoch 721/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4591 - accuracy: 0.8086 - val_loss: 0.4304 - val_accuracy: 0.8145\n",
            "Epoch 722/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4549 - accuracy: 0.8069 - val_loss: 0.4309 - val_accuracy: 0.8176\n",
            "Epoch 723/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.7973 - val_loss: 0.4304 - val_accuracy: 0.8145\n",
            "Epoch 724/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4428 - accuracy: 0.8148 - val_loss: 0.4302 - val_accuracy: 0.8113\n",
            "Epoch 725/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4599 - accuracy: 0.7971 - val_loss: 0.4299 - val_accuracy: 0.8113\n",
            "Epoch 726/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4562 - accuracy: 0.7967 - val_loss: 0.4292 - val_accuracy: 0.8176\n",
            "Epoch 727/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4522 - accuracy: 0.8147 - val_loss: 0.4312 - val_accuracy: 0.8145\n",
            "Epoch 728/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4500 - accuracy: 0.8162 - val_loss: 0.4293 - val_accuracy: 0.8145\n",
            "Epoch 729/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4651 - accuracy: 0.8012 - val_loss: 0.4298 - val_accuracy: 0.8145\n",
            "Epoch 730/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4277 - accuracy: 0.8314 - val_loss: 0.4306 - val_accuracy: 0.8113\n",
            "Epoch 731/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4669 - accuracy: 0.7940 - val_loss: 0.4298 - val_accuracy: 0.8113\n",
            "Epoch 732/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4834 - accuracy: 0.7862 - val_loss: 0.4306 - val_accuracy: 0.8145\n",
            "Epoch 733/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4444 - accuracy: 0.8032 - val_loss: 0.4308 - val_accuracy: 0.8145\n",
            "Epoch 734/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4538 - accuracy: 0.8078 - val_loss: 0.4320 - val_accuracy: 0.8145\n",
            "Epoch 735/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4549 - accuracy: 0.8062 - val_loss: 0.4317 - val_accuracy: 0.8145\n",
            "Epoch 736/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4608 - accuracy: 0.8109 - val_loss: 0.4308 - val_accuracy: 0.8145\n",
            "Epoch 737/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4513 - accuracy: 0.8071 - val_loss: 0.4303 - val_accuracy: 0.8113\n",
            "Epoch 738/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4747 - accuracy: 0.7938 - val_loss: 0.4316 - val_accuracy: 0.8145\n",
            "Epoch 739/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4582 - accuracy: 0.8102 - val_loss: 0.4303 - val_accuracy: 0.8113\n",
            "Epoch 740/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4392 - accuracy: 0.8202 - val_loss: 0.4305 - val_accuracy: 0.8145\n",
            "Epoch 741/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4514 - accuracy: 0.8102 - val_loss: 0.4300 - val_accuracy: 0.8113\n",
            "Epoch 742/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4640 - accuracy: 0.7984 - val_loss: 0.4301 - val_accuracy: 0.8113\n",
            "Epoch 743/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4614 - accuracy: 0.7956 - val_loss: 0.4297 - val_accuracy: 0.8145\n",
            "Epoch 744/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4575 - accuracy: 0.8058 - val_loss: 0.4298 - val_accuracy: 0.8113\n",
            "Epoch 745/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4612 - accuracy: 0.8063 - val_loss: 0.4301 - val_accuracy: 0.8113\n",
            "Epoch 746/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4360 - accuracy: 0.8197 - val_loss: 0.4306 - val_accuracy: 0.8145\n",
            "Epoch 747/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4675 - accuracy: 0.8013 - val_loss: 0.4306 - val_accuracy: 0.8145\n",
            "Epoch 748/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4814 - accuracy: 0.7879 - val_loss: 0.4309 - val_accuracy: 0.8176\n",
            "Epoch 749/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4763 - accuracy: 0.7902 - val_loss: 0.4296 - val_accuracy: 0.8145\n",
            "Epoch 750/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4437 - accuracy: 0.8112 - val_loss: 0.4299 - val_accuracy: 0.8145\n",
            "Epoch 751/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4415 - accuracy: 0.8140 - val_loss: 0.4302 - val_accuracy: 0.8113\n",
            "Epoch 752/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4447 - accuracy: 0.8221 - val_loss: 0.4301 - val_accuracy: 0.8113\n",
            "Epoch 753/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4409 - accuracy: 0.8087 - val_loss: 0.4310 - val_accuracy: 0.8145\n",
            "Epoch 754/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4834 - accuracy: 0.7982 - val_loss: 0.4297 - val_accuracy: 0.8145\n",
            "Epoch 755/1000\n",
            "40/40 [==============================] - 0s 12ms/step - loss: 0.4406 - accuracy: 0.8038 - val_loss: 0.4308 - val_accuracy: 0.8145\n",
            "Epoch 756/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4653 - accuracy: 0.7930 - val_loss: 0.4301 - val_accuracy: 0.8113\n",
            "Epoch 757/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4482 - accuracy: 0.8084 - val_loss: 0.4313 - val_accuracy: 0.8176\n",
            "Epoch 758/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4591 - accuracy: 0.8089 - val_loss: 0.4306 - val_accuracy: 0.8145\n",
            "Epoch 759/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4316 - accuracy: 0.8180 - val_loss: 0.4296 - val_accuracy: 0.8176\n",
            "Epoch 760/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4633 - accuracy: 0.8036 - val_loss: 0.4311 - val_accuracy: 0.8145\n",
            "Epoch 761/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4470 - accuracy: 0.8193 - val_loss: 0.4294 - val_accuracy: 0.8145\n",
            "Epoch 762/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4649 - accuracy: 0.8030 - val_loss: 0.4312 - val_accuracy: 0.8145\n",
            "Epoch 763/1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4195 - accuracy: 0.8240 - val_loss: 0.4303 - val_accuracy: 0.8113\n",
            "Epoch 00763: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f285bec2550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_K2D6YlJS9B"
      },
      "source": [
        "##Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "EFkqAN0imgZG",
        "outputId": "02b5dbcd-593b-4e28-9483-427d934dcc17"
      },
      "source": [
        "#RESULTS\n",
        "losses = pd.DataFrame(model.history.history)\n",
        "losses_plot = losses.plot()\n",
        "losses_plot.set(xlabel = \"epochs\", ylabel = \"metrics\", title = 'Training LSTM (w/ MobileNetV2) on URFD_Multicam_first_half')\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0.5, 'metrics'),\n",
              " Text(0.5, 0, 'epochs'),\n",
              " Text(0.5, 1.0, 'Training LSTM (w/ MobileNetV2) on URFD_Multicam_first_half')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEPVgGK9mgZG",
        "outputId": "17faee65-e912-45ea-f9f6-f6a6813f5b02"
      },
      "source": [
        "predictions = model.predict_classes(X_test)\n",
        "print(classification_report(y_test,predictions, target_names=['label 0: No Fall','label 1:    Fall'], digits = 3))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                  precision    recall  f1-score   support\n",
            "\n",
            "label 0: No Fall      0.833     0.867     0.850       196\n",
            "label 1:    Fall      0.772     0.721     0.746       122\n",
            "\n",
            "        accuracy                          0.811       318\n",
            "       macro avg      0.803     0.794     0.798       318\n",
            "    weighted avg      0.810     0.811     0.810       318\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}